{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMfjO/KCVv6D/0rAsLScGHz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonanew/noise_detection/blob/main/KMeans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install rdflib for KG\n",
        "!pip install rdflib\n",
        "\n",
        "# Install noise package for noise generation\n",
        "!pip install noise\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-y8akBVtcqX",
        "outputId": "ac23dcc2-cfd9-4d26-a650-3b42ac5ba91b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdflib\n",
            "  Downloading rdflib-7.1.4-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from rdflib) (3.2.3)\n",
            "Downloading rdflib-7.1.4-py3-none-any.whl (565 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/565.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.1/565.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdflib\n",
            "Successfully installed rdflib-7.1.4\n",
            "Collecting noise\n",
            "  Downloading noise-1.2.2.zip (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: noise\n",
            "  Building wheel for noise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for noise: filename=noise-1.2.2-cp311-cp311-linux_x86_64.whl size=56276 sha256=0641a3b08898df23a8e95a325fa170d51a4f67f46964d916329e43b910bc7c10\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/25/2e/af6d1bcc91a8f99af0f651f8718b9ab999720a21c6d4149091\n",
            "Successfully built noise\n",
            "Installing collected packages: noise\n",
            "Successfully installed noise-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joCJbcj_vIQQ",
        "outputId": "f327ff58-b68b-40ed-9b9c-0e4e3e49a2ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XZRc2HPgK_xS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74580c3b-926b-49bd-9961-abc86ee92268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global magnitude stats (after outlier removal): Mean = 0.753240, Std = 0.638734\n",
            "Per-activity magnitude stats:\n",
            "   activity  actual_mean  actual_std  sample_count\n",
            "0      dws     0.575685    0.426152        131856\n",
            "1      jog     1.445474    0.905656        134231\n",
            "2      ups     0.447230    0.337824        157285\n",
            "3      wlk     0.691151    0.471883        344288\n",
            "Original data size: 767660\n",
            "Processing Fold 1\n",
            "Training set size: 614128, Test set size: 153532\n",
            "Optimal number of clusters for Fold 1: 7\n",
            "Processing noise fraction: 2.0% in Fold 1\n",
            "Processing noise fraction: 5.0% in Fold 1\n",
            "Processing noise fraction: 10.0% in Fold 1\n",
            "Processing noise fraction: 20.0% in Fold 1\n",
            "Processing Fold 2\n",
            "Training set size: 614128, Test set size: 153532\n",
            "Optimal number of clusters for Fold 2: 11\n",
            "Processing noise fraction: 2.0% in Fold 2\n",
            "Processing noise fraction: 5.0% in Fold 2\n",
            "Processing noise fraction: 10.0% in Fold 2\n",
            "Processing noise fraction: 20.0% in Fold 2\n",
            "Processing Fold 3\n",
            "Training set size: 614128, Test set size: 153532\n",
            "Optimal number of clusters for Fold 3: 11\n",
            "Processing noise fraction: 2.0% in Fold 3\n",
            "Processing noise fraction: 5.0% in Fold 3\n",
            "Processing noise fraction: 10.0% in Fold 3\n",
            "Processing noise fraction: 20.0% in Fold 3\n",
            "Processing Fold 4\n",
            "Training set size: 614128, Test set size: 153532\n",
            "Optimal number of clusters for Fold 4: 11\n",
            "Processing noise fraction: 2.0% in Fold 4\n",
            "Processing noise fraction: 5.0% in Fold 4\n",
            "Processing noise fraction: 10.0% in Fold 4\n",
            "Processing noise fraction: 20.0% in Fold 4\n",
            "Processing Fold 5\n",
            "Training set size: 614128, Test set size: 153532\n",
            "Optimal number of clusters for Fold 5: 11\n",
            "Processing noise fraction: 2.0% in Fold 5\n",
            "Processing noise fraction: 5.0% in Fold 5\n",
            "Processing noise fraction: 10.0% in Fold 5\n",
            "Processing noise fraction: 20.0% in Fold 5\n",
            "\n",
            "Consolidated Evaluation Results:\n",
            "   Noise Fraction (%)                  Method  Precision    Recall  F1 Score  \\\n",
            "0                 2.0  Hybrid (Cluster-based)   0.754201  0.405548  0.526943   \n",
            "1                 2.0    Traditional (Global)   0.292587  0.297154  0.294851   \n",
            "2                 5.0  Hybrid (Cluster-based)   0.886237  0.403064  0.553978   \n",
            "3                 5.0    Traditional (Global)   0.515256  0.296256  0.376203   \n",
            "4                10.0  Hybrid (Cluster-based)   0.943034  0.404653  0.566287   \n",
            "5                10.0    Traditional (Global)   0.692959  0.296574  0.415374   \n",
            "6                20.0  Hybrid (Cluster-based)   0.973477  0.403947  0.570964   \n",
            "7                20.0    Traditional (Global)   0.835085  0.296508  0.437629   \n",
            "\n",
            "   Noise Detected (%)  \n",
            "0           40.554757  \n",
            "1           29.715395  \n",
            "2           40.306439  \n",
            "3           29.625622  \n",
            "4           40.465344  \n",
            "5           29.657358  \n",
            "6           40.394722  \n",
            "7           29.650790  \n",
            "Noisy dataset saved to '/content/drive/My Drive/ColabNotebooks/noisy_results_kmeans_gaussian.csv'.\n",
            "Evaluation results saved to '/content/drive/My Drive/ColabNotebooks/evaluation_results_kmeans_gaussian.csv'.\n",
            "\n",
            "Z-score stats (noisy dataset, last noise level of last fold):\n",
            "              Z_score  traditional_Z_score\n",
            "count  767660.000000        767660.000000\n",
            "mean        0.005873             0.000185\n",
            "std         2.286684             1.341811\n",
            "min       -24.650705            -8.994172\n",
            "25%        -0.875000            -0.678279\n",
            "50%        -0.120000            -0.271224\n",
            "75%         0.825000             0.448950\n",
            "max        25.081129            15.270974\n",
            "Noise detection summary (hybrid, noisy dataset, last noise level of last fold):\n",
            " is_noise\n",
            "False    704119\n",
            "True      63541\n",
            "Name: count, dtype: int64\n",
            "Noise detection summary (traditional, noisy dataset, last noise level of last fold):\n",
            " is_noise_traditional\n",
            "False    713138\n",
            "True      54522\n",
            "Name: count, dtype: int64\n",
            "Total noise points introduced (last noise level of last fold): 153948\n",
            "Hybrid method detected (last noise level of last fold): 62253 (40.44%)\n",
            "Traditional method detected (last noise level of last fold): 45556 (29.59%)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdflib import Graph\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Paths to sensor reading csv file data and knowledge graph\n",
        "data_path = \"/content/drive/My Drive/ColabNotebooks/motion_sensor_readings.csv\"\n",
        "kg_path = \"/content/drive/My Drive/ColabNotebooks/motion_sense_ssn_kg.ttl\"\n",
        "\n",
        "# Load knowledge graph\n",
        "g = Graph()\n",
        "try:\n",
        "    g.parse(kg_path, format='turtle')\n",
        "except Exception as e:\n",
        "    print(f\"Error parsing knowledge graph: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "# Query for participant characteristics\n",
        "query = \"\"\"\n",
        "PREFIX ms: <http://example.org/motion-sense#>\n",
        "SELECT ?p ?code ?age ?gender ?height ?weight\n",
        "WHERE {\n",
        "    ?p a ms:Participant ;\n",
        "       ms:hasCode ?code ;\n",
        "       ms:hasAge ?age ;\n",
        "       ms:hasGender ?gender ;\n",
        "       ms:hasHeightCm ?height ;\n",
        "       ms:hasWeightKg ?weight .\n",
        "}\n",
        "\"\"\"\n",
        "results = g.query(query)\n",
        "participants = []\n",
        "for row in results:\n",
        "    participants.append({\n",
        "        'participant': str(row.code).strip().upper(),\n",
        "        'age': int(row.age),\n",
        "        'gender': int(row.gender),\n",
        "        'height': float(row.height),\n",
        "        'weight': float(row.weight)\n",
        "    })\n",
        "participants_df = pd.DataFrame(participants)\n",
        "\n",
        "if participants_df.empty:\n",
        "    print(\"Error: No participants found in knowledge graph.\")\n",
        "    exit(1)\n",
        "\n",
        "# Query for activity plausible ranges\n",
        "query_ranges = \"\"\"\n",
        "PREFIX activity: <http://example.org/activity-recognition#>\n",
        "SELECT ?activityCode ?min ?max\n",
        "WHERE {\n",
        "    ?act a activity:Activity ;\n",
        "         activity:hasActivityCode ?activityCode ;\n",
        "         activity:hasMinAcceleration ?min ;\n",
        "         activity:hasMaxAcceleration ?max .\n",
        "}\n",
        "\"\"\"\n",
        "results_ranges = g.query(query_ranges)\n",
        "activity_ranges = {}\n",
        "for row in results_ranges:\n",
        "    activity_code = str(row.activityCode).strip().lower()\n",
        "    activity_ranges[activity_code] = {\n",
        "        'min': float(row.min),\n",
        "        'max': float(row.max)\n",
        "    }\n",
        "\n",
        "if not activity_ranges:\n",
        "    print(\"Error: No activity ranges found in knowledge graph.\")\n",
        "    exit(1)\n",
        "\n",
        "# Load sensor readings csv file data\n",
        "try:\n",
        "    df = pd.read_csv(data_path)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading sensor data: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "# Parse sensor_id with validation\n",
        "def parse_sensor_id(sid):\n",
        "    parts = sid.split('_')\n",
        "    if len(parts) >= 5:\n",
        "        return parts[0].strip().upper(), parts[3], parts[4]\n",
        "    return None, None, None\n",
        "\n",
        "df['participant'], df['activity'], df['sensor_type'] = zip(*df['sensor_id'].apply(parse_sensor_id))\n",
        "df = df.dropna(subset=['participant'])\n",
        "\n",
        "# Filter for accelerometer data\n",
        "df = df[(df['sensor_type'] == 'Accelerometer') &\n",
        "        (df['property'].isin(['UserAccelerationX', 'UserAccelerationY', 'UserAccelerationZ']))]\n",
        "\n",
        "# Convert measurement to numeric, drop invalid entries\n",
        "df['measurement'] = pd.to_numeric(df['measurement'], errors='coerce')\n",
        "df = df.dropna(subset=['measurement'])\n",
        "\n",
        "if df.empty:\n",
        "    print(\"Error: No valid accelerometer data after cleaning.\")\n",
        "    exit(1)\n",
        "\n",
        "# Pivot to get X, Y, Z\n",
        "acc_df = df.pivot_table(index=['timestamp', 'sensor_id', 'participant', 'activity'],\n",
        "                        columns='property', values='measurement', aggfunc='first').reset_index()\n",
        "\n",
        "# Drop rows with missing or invalid acceleration components\n",
        "acc_df = acc_df.dropna(subset=['UserAccelerationX', 'UserAccelerationY', 'UserAccelerationZ'])\n",
        "for col in ['UserAccelerationX', 'UserAccelerationY', 'UserAccelerationZ']:\n",
        "    acc_df[col] = pd.to_numeric(acc_df[col], errors='coerce')\n",
        "acc_df = acc_df.dropna(subset=['UserAccelerationX', 'UserAccelerationY', 'UserAccelerationZ'])\n",
        "\n",
        "if acc_df.empty:\n",
        "    print(\"Error: No valid data after pivot and cleaning.\")\n",
        "    exit(1)\n",
        "\n",
        "# Compute magnitude\n",
        "acc_df['magnitude'] = np.sqrt(acc_df['UserAccelerationX']**2 +\n",
        "                              acc_df['UserAccelerationY']**2 +\n",
        "                              acc_df['UserAccelerationZ']**2)\n",
        "\n",
        "# Compute global mean and std for magnitude (for traditional Z-score)\n",
        "global_magnitude_mean = acc_df['magnitude'].mean()\n",
        "global_magnitude_std = acc_df['magnitude'].std()\n",
        "print(f\"Global magnitude stats: Mean = {global_magnitude_mean:.6f}, Std = {global_magnitude_std:.6f}\")\n",
        "\n",
        "# Compute per-activity stats for reference on cleaned data\n",
        "activity_stats_df = acc_df.groupby('activity')['magnitude'].agg(['mean', 'std', 'count']).reset_index()\n",
        "activity_stats_df.columns = ['activity', 'actual_mean', 'actual_std', 'sample_count']\n",
        "\n",
        "# Ensure sufficient samples and smooth std\n",
        "activity_stats_df = activity_stats_df[activity_stats_df['sample_count'] >= 100]\n",
        "global_activity_std = activity_stats_df['actual_std'].mean()\n",
        "activity_stats_df['actual_std'] = activity_stats_df['actual_std'].apply(lambda x: max(x, global_activity_std * 0.1))\n",
        "\n",
        "# Debug: Print per-activity stats\n",
        "print(\"Per-activity magnitude stats:\\n\", activity_stats_df[['activity', 'actual_mean', 'actual_std', 'sample_count']])\n",
        "\n",
        "# Merge with participant characteristics for clustering\n",
        "merged_df = pd.merge(acc_df, participants_df, on='participant', how='inner')\n",
        "\n",
        "if merged_df.empty:\n",
        "    print(\"Error: No matching participants found after merging.\")\n",
        "    exit(1)\n",
        "\n",
        "# Debug: Print original data size\n",
        "print(\"Original data size:\", len(merged_df))\n",
        "\n",
        "# Initialize 5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "results_list = []\n",
        "\n",
        "# Iterate over folds\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(merged_df), 1):\n",
        "    print(f\"Processing Fold {fold}\")\n",
        "    train_df = merged_df.iloc[train_index].copy()\n",
        "    test_df = merged_df.iloc[test_index].copy()\n",
        "    print(f\"Training set size: {len(train_df)}, Test set size: {len(test_df)}\")\n",
        "\n",
        "    # Prepare data for clustering on training set, including magnitude\n",
        "    X_cluster_train = train_df[['age', 'gender', 'height', 'weight', 'magnitude', 'activity']]\n",
        "    scaler = RobustScaler()\n",
        "    X_numeric_train = scaler.fit_transform(X_cluster_train[['age', 'gender', 'height', 'weight', 'magnitude']])\n",
        "    X_activity_train = pd.get_dummies(X_cluster_train['activity'], prefix='activity')\n",
        "    X_scaled_train = np.hstack([X_numeric_train, X_activity_train])\n",
        "\n",
        "    # Determine optimal number of clusters using the elbow method on training set\n",
        "    wcss = []\n",
        "    max_clusters = 11\n",
        "    for i in range(2, max_clusters + 1):\n",
        "        kmeans = KMeans(n_clusters=i, random_state=42)\n",
        "        kmeans.fit(X_scaled_train)\n",
        "        wcss.append(kmeans.inertia_)\n",
        "\n",
        "    # Plot the elbow curve for this fold (optional, can be disabled for efficiency)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(range(2, max_clusters + 1), wcss, marker='o')\n",
        "    plt.title(f'Elbow Method for Optimal Number of Clusters - Fold {fold}')\n",
        "    plt.xlabel('Number of Clusters')\n",
        "    plt.ylabel('WCSS')\n",
        "    plt.savefig(f'/content/drive/My Drive/ColabNotebooks/elbow_curve_fold_{fold}.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Choose the optimal number of clusters\n",
        "    optimal_clusters = 11  # Placeholder, adjust based on elbow curve\n",
        "    for i in range(2, len(wcss) - 1):\n",
        "        if (wcss[i-1] - wcss[i]) / (wcss[i] - wcss[i+1]) < 0.5:\n",
        "            optimal_clusters = i + 2\n",
        "            break\n",
        "    print(f\"Optimal number of clusters for Fold {fold}: {optimal_clusters}\")\n",
        "\n",
        "    # Perform K-means clustering with optimal number of clusters on training set\n",
        "    kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
        "    train_cluster_labels = kmeans.fit_predict(X_scaled_train)\n",
        "\n",
        "    # Assign clusters to test set using the trained K-means model\n",
        "    X_cluster_test = test_df[['age', 'gender', 'height', 'weight', 'magnitude', 'activity']]\n",
        "    X_numeric_test = scaler.transform(X_cluster_test[['age', 'gender', 'height', 'weight', 'magnitude']])\n",
        "    X_activity_test = pd.get_dummies(X_cluster_test['activity'], prefix='activity')\n",
        "    # Align columns between train and test activity dummies\n",
        "    X_activity_test = X_activity_test.reindex(columns=X_activity_train.columns, fill_value=0)\n",
        "    X_scaled_test = np.hstack([X_numeric_test, X_activity_test])\n",
        "    test_cluster_labels = kmeans.predict(X_scaled_test)\n",
        "\n",
        "    # Add cluster labels to train and test dataframes\n",
        "    train_df['cluster'] = train_cluster_labels\n",
        "    test_df['cluster'] = test_cluster_labels\n",
        "\n",
        "    # Combine train and test dataframes for this fold\n",
        "    fold_df = pd.concat([train_df, test_df], axis=0)\n",
        "\n",
        "    # Assign cluster mean and std for Z-score calculation using K-means clusters\n",
        "    cluster_means = train_df.groupby('cluster')['magnitude'].mean().to_dict()\n",
        "    cluster_stds = train_df.groupby('cluster')['magnitude'].std().to_dict()\n",
        "    fold_df['cluster_mu'] = fold_df['cluster'].map(cluster_means)\n",
        "    fold_df['cluster_sigma'] = fold_df['cluster'].map(cluster_stds).fillna(global_activity_std)\n",
        "\n",
        "    # Compute Z-scores using cluster-based statistics\n",
        "    fold_df['Z_score'] = (fold_df['magnitude'] - fold_df['cluster_mu']) / fold_df['cluster_sigma'].replace(0, np.nan)\n",
        "    fold_df['traditional_Z_score'] = (fold_df['magnitude'] - global_magnitude_mean) / global_magnitude_std\n",
        "\n",
        "    # Add global mean and std to output\n",
        "    fold_df['global_magnitude_mean'] = global_magnitude_mean\n",
        "    fold_df['global_magnitude_std'] = global_magnitude_std\n",
        "\n",
        "    # Apply activity-specific plausible ranges\n",
        "    fold_df['activity'] = fold_df['activity'].str.lower()\n",
        "    default_min_plausible = 0\n",
        "    default_max_plausible = 10\n",
        "    fold_df['min_plausible'] = fold_df['activity'].map(lambda x: activity_ranges.get(x, {'min': default_min_plausible})['min'])\n",
        "    fold_df['max_plausible'] = fold_df['activity'].map(lambda x: activity_ranges.get(x, {'max': default_max_plausible})['max'])\n",
        "\n",
        "    # Determine if observations are outside plausible range\n",
        "    fold_df['outside_plausible'] = (fold_df['magnitude'] < fold_df['min_plausible']) | (fold_df['magnitude'] > fold_df['max_plausible'])\n",
        "\n",
        "    # Determine anomaly\n",
        "    threshold = 2\n",
        "    fold_df['is_anomaly'] = np.abs(fold_df['Z_score']) > threshold\n",
        "    fold_df['is_anomaly_traditional'] = np.abs(fold_df['traditional_Z_score']) > threshold\n",
        "\n",
        "    # Label noise\n",
        "    fold_df['is_noise'] = fold_df['is_anomaly'] & fold_df['outside_plausible']\n",
        "    fold_df['is_noise_traditional'] = fold_df['is_anomaly_traditional'] & fold_df['outside_plausible']\n",
        "\n",
        "    # Round numerical columns in fold_df to 2 decimal places\n",
        "    numerical_cols = fold_df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    fold_df[numerical_cols] = fold_df[numerical_cols].round(2)\n",
        "\n",
        "    # Function to introduce Gaussian noise\n",
        "    def introduce_gaussian_noise(df, noise_level=0.1, noise_fraction=0.05):\n",
        "        noisy_df = df.copy()\n",
        "        mask = np.random.rand(len(noisy_df)) < noise_fraction\n",
        "        noise = np.random.normal(0, noise_level, size=len(noisy_df))\n",
        "        noisy_df['magnitude'] = noisy_df['magnitude'] + noise * mask\n",
        "        noisy_df['is_true_noise'] = mask.astype(int)  # Ground truth: 1 for noisy, 0 for normal\n",
        "        return noisy_df\n",
        "\n",
        "    # List of noise fractions to test\n",
        "    noise_fractions = [0.02, 0.05, 0.10, 0.20]\n",
        "\n",
        "    # Iterate over noise levels\n",
        "    for noise_fraction in noise_fractions:\n",
        "        print(f\"Processing noise fraction: {noise_fraction*100}% in Fold {fold}\")\n",
        "        # Introduce noise to the dataset\n",
        "        noisy_df = introduce_gaussian_noise(fold_df, noise_level=2 * global_magnitude_std, noise_fraction=noise_fraction)\n",
        "\n",
        "        # Apply anomaly detection - Hybrid method\n",
        "        noisy_df['Z_score'] = (noisy_df['magnitude'] - noisy_df['cluster_mu']) / noisy_df['cluster_sigma'].replace(0, np.nan)\n",
        "        noisy_df['is_anomaly'] = np.abs(noisy_df['Z_score']) > threshold\n",
        "        noisy_df['outside_plausible'] = (noisy_df['magnitude'] < noisy_df['min_plausible']) | (noisy_df['magnitude'] > noisy_df['max_plausible'])\n",
        "        noisy_df['is_noise'] = noisy_df['is_anomaly'] & noisy_df['outside_plausible']\n",
        "\n",
        "        # Apply anomaly detection - Traditional method\n",
        "        noisy_df['traditional_Z_score'] = (noisy_df['magnitude'] - global_magnitude_mean) / global_magnitude_std\n",
        "        noisy_df['is_anomaly_traditional'] = np.abs(noisy_df['traditional_Z_score']) > threshold\n",
        "        noisy_df['is_noise_traditional'] = noisy_df['is_anomaly_traditional'] & noisy_df['outside_plausible']\n",
        "\n",
        "        # Evaluate performance\n",
        "        y_true = noisy_df['is_true_noise']\n",
        "        y_pred_hybrid = noisy_df['is_noise'].astype(int)\n",
        "        y_pred_traditional = noisy_df['is_noise_traditional'].astype(int)\n",
        "\n",
        "        precision_hybrid = precision_score(y_true, y_pred_hybrid)\n",
        "        recall_hybrid = recall_score(y_true, y_pred_hybrid)\n",
        "        f1_hybrid = f1_score(y_true, y_pred_hybrid)\n",
        "\n",
        "        precision_traditional = precision_score(y_true, y_pred_traditional)\n",
        "        recall_traditional = recall_score(y_true, y_pred_traditional)\n",
        "        f1_traditional = f1_score(y_true, y_pred_traditional)\n",
        "\n",
        "        # Calculate percentage of noise detected\n",
        "        total_noise_points = y_true.sum()\n",
        "        hybrid_detected = y_pred_hybrid[y_true == 1].sum()\n",
        "        traditional_detected = y_pred_traditional[y_true == 1].sum()\n",
        "        hybrid_noise_percentage = (hybrid_detected / total_noise_points * 100) if total_noise_points > 0 else 0\n",
        "        traditional_noise_percentage = (traditional_detected / total_noise_points * 100) if total_noise_points > 0 else 0\n",
        "\n",
        "        # Store results for this noise level and fold\n",
        "        results_list.append({\n",
        "            'Fold': fold,\n",
        "            'Algorithm': 'K-means',\n",
        "            'Noise Fraction (%)': noise_fraction * 100,\n",
        "            'Method': 'Hybrid (Cluster-based)',\n",
        "            'Precision': precision_hybrid,\n",
        "            'Recall': recall_hybrid,\n",
        "            'F1 Score': f1_hybrid,\n",
        "            'Noise Detected (%)': hybrid_noise_percentage\n",
        "        })\n",
        "        results_list.append({\n",
        "            'Fold': fold,\n",
        "            'Algorithm': 'K-means',\n",
        "            'Noise Fraction (%)': noise_fraction * 100,\n",
        "            'Method': 'Traditional (Global)',\n",
        "            'Precision': precision_traditional,\n",
        "            'Recall': recall_traditional,\n",
        "            'F1 Score': f1_traditional,\n",
        "            'Noise Detected (%)': traditional_noise_percentage\n",
        "        })\n",
        "\n",
        "# Create consolidated results table\n",
        "results_df = pd.DataFrame(results_list)\n",
        "print(\"\\nConsolidated Evaluation Results:\")\n",
        "print(results_df.groupby(['Noise Fraction (%)', 'Method']).agg({\n",
        "    'Precision': 'mean',\n",
        "    'Recall': 'mean',\n",
        "    'F1 Score': 'mean',\n",
        "    'Noise Detected (%)': 'mean'\n",
        "}).reset_index())\n",
        "\n",
        "# Save noisy dataset and results for the last fold\n",
        "try:\n",
        "    noisy_df.to_csv('/content/drive/My Drive/ColabNotebooks/noisy_results_kmeans_gaussian.csv', index=False)\n",
        "    print(f\"Noisy dataset saved to '/content/drive/My Drive/ColabNotebooks/noisy_results_kmeans_gaussian.csv'.\")\n",
        "    results_df.to_csv('/content/drive/My Drive/ColabNotebooks/evaluation_results_kmeans_gaussian.csv', index=False)\n",
        "    print(f\"Evaluation results saved to '/content/drive/My Drive/ColabNotebooks/evaluation_results_kmeans_gaussian.csv'.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving files: {e}\")\n",
        "\n",
        "# Debug: Print summary for the last noise level of the last fold\n",
        "print(\"\\nZ-score stats (noisy dataset, last noise level of last fold):\\n\", noisy_df[['Z_score', 'traditional_Z_score']].describe())\n",
        "print(\"Noise detection summary (hybrid, noisy dataset, last noise level of last fold):\\n\", noisy_df['is_noise'].value_counts())\n",
        "print(\"Noise detection summary (traditional, noisy dataset, last noise level of last fold):\\n\", noisy_df['is_noise_traditional'].value_counts())\n",
        "print(f\"Total noise points introduced (last noise level of last fold): {total_noise_points}\")\n",
        "print(f\"Hybrid method detected (last noise level of last fold): {hybrid_detected} ({hybrid_noise_percentage:.2f}%)\")\n",
        "print(f\"Traditional method detected (last noise level of last fold): {traditional_detected} ({traditional_noise_percentage:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdflib import Graph\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from scipy.stats import gennorm\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Paths to sensor reading csv file data and knowledge graph\n",
        "data_path = \"/content/drive/My Drive/ColabNotebooks/motion_sensor_readings.csv\"\n",
        "kg_path = \"/content/drive/My Drive/ColabNotebooks/motion_sense_ssn_kg.ttl\"\n",
        "\n",
        "# Load knowledge graph\n",
        "g = Graph()\n",
        "try:\n",
        "    g.parse(kg_path, format='turtle')\n",
        "except Exception as e:\n",
        "    print(f\"Error parsing knowledge graph: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "# Query for participant characteristics\n",
        "query = \"\"\"\n",
        "PREFIX ms: <http://example.org/motion-sense#>\n",
        "SELECT ?p ?code ?age ?gender ?height ?weight\n",
        "WHERE {\n",
        "    ?p a ms:Participant ;\n",
        "       ms:hasCode ?code ;\n",
        "       ms:hasAge ?age ;\n",
        "       ms:hasGender ?gender ;\n",
        "       ms:hasHeightCm ?height ;\n",
        "       ms:hasWeightKg ?weight .\n",
        "}\n",
        "\"\"\"\n",
        "results = g.query(query)\n",
        "participants = []\n",
        "for row in results:\n",
        "    participants.append({\n",
        "        'participant': str(row.code).strip().upper(),\n",
        "        'age': int(row.age),\n",
        "        'gender': int(row.gender),\n",
        "        'height': float(row.height),\n",
        "        'weight': float(row.weight)\n",
        "    })\n",
        "participants_df = pd.DataFrame(participants)\n",
        "\n",
        "if participants_df.empty:\n",
        "    print(\"Error: No participants found in knowledge graph.\")\n",
        "    exit(1)\n",
        "\n",
        "# Query for activity plausible ranges\n",
        "query_ranges = \"\"\"\n",
        "PREFIX activity: <http://example.org/activity-recognition#>\n",
        "SELECT ?activityCode ?min ?max\n",
        "WHERE {\n",
        "    ?act a activity:Activity ;\n",
        "         activity:hasActivityCode ?activityCode ;\n",
        "         activity:hasMinAcceleration ?min ;\n",
        "         activity:hasMaxAcceleration ?max .\n",
        "}\n",
        "\"\"\"\n",
        "results_ranges = g.query(query_ranges)\n",
        "activity_ranges = {}\n",
        "for row in results_ranges:\n",
        "    activity_code = str(row.activityCode).strip().lower()\n",
        "    activity_ranges[activity_code] = {\n",
        "        'min': float(row.min),\n",
        "        'max': float(row.max)\n",
        "    }\n",
        "\n",
        "if not activity_ranges:\n",
        "    print(\"Error: No activity ranges found in knowledge graph.\")\n",
        "    exit(1)\n",
        "\n",
        "# Load sensor readings csv file data\n",
        "try:\n",
        "    df = pd.read_csv(data_path)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading sensor data: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "# Parse sensor_id with validation\n",
        "def parse_sensor_id(sid):\n",
        "    parts = sid.split('_')\n",
        "    if len(parts) >= 5:\n",
        "        return parts[0].strip().upper(), parts[3], parts[4]\n",
        "    return None, None, None\n",
        "\n",
        "df['participant'], df['activity'], df['sensor_type'] = zip(*df['sensor_id'].apply(parse_sensor_id))\n",
        "df = df.dropna(subset=['participant'])\n",
        "\n",
        "# Filter for accelerometer data\n",
        "df = df[(df['sensor_type'] == 'Accelerometer') &\n",
        "        (df['property'].isin(['UserAccelerationX', 'UserAccelerationY', 'UserAccelerationZ']))]\n",
        "\n",
        "# Convert measurement to numeric, drop invalid entries\n",
        "df['measurement'] = pd.to_numeric(df['measurement'], errors='coerce')\n",
        "df = df.dropna(subset=['measurement'])\n",
        "\n",
        "if df.empty:\n",
        "    print(\"Error: No valid accelerometer data after cleaning.\")\n",
        "    exit(1)\n",
        "\n",
        "# Pivot to get X, Y, Z\n",
        "acc_df = df.pivot_table(index=['timestamp', 'sensor_id', 'participant', 'activity'],\n",
        "                        columns='property', values='measurement', aggfunc='first').reset_index()\n",
        "\n",
        "# Drop rows with missing or invalid acceleration components\n",
        "acc_df = acc_df.dropna(subset=['UserAccelerationX', 'UserAccelerationY', 'UserAccelerationZ'])\n",
        "for col in ['UserAccelerationX', 'UserAccelerationY', 'UserAccelerationZ']:\n",
        "    acc_df[col] = pd.to_numeric(acc_df[col], errors='coerce')\n",
        "acc_df = acc_df.dropna(subset=['UserAccelerationX', 'UserAccelerationY', 'UserAccelerationZ'])\n",
        "\n",
        "if acc_df.empty:\n",
        "    print(\"Error: No valid data after pivot and cleaning.\")\n",
        "    exit(1)\n",
        "\n",
        "# Compute magnitude\n",
        "acc_df['magnitude'] = np.sqrt(acc_df['UserAccelerationX']**2 +\n",
        "                              acc_df['UserAccelerationY']**2 +\n",
        "                              acc_df['UserAccelerationZ']**2)\n",
        "\n",
        "# Compute global mean and std for magnitude (for traditional Z-score)\n",
        "global_magnitude_mean = acc_df['magnitude'].mean()\n",
        "global_magnitude_std = acc_df['magnitude'].std()\n",
        "print(f\"Global magnitude stats: Mean = {global_magnitude_mean:.6f}, Std = {global_magnitude_std:.6f}\")\n",
        "\n",
        "# Compute per-activity stats for reference on cleaned data\n",
        "activity_stats_df = acc_df.groupby('activity')['magnitude'].agg(['mean', 'std', 'count']).reset_index()\n",
        "activity_stats_df.columns = ['activity', 'actual_mean', 'actual_std', 'sample_count']\n",
        "\n",
        "# Ensure sufficient samples and smooth std\n",
        "activity_stats_df = activity_stats_df[activity_stats_df['sample_count'] >= 100]\n",
        "global_activity_std = activity_stats_df['actual_std'].mean()\n",
        "activity_stats_df['actual_std'] = activity_stats_df['actual_std'].apply(lambda x: max(x, global_activity_std * 0.1))\n",
        "\n",
        "# Debug: Print per-activity stats\n",
        "print(\"Per-activity magnitude stats:\\n\", activity_stats_df[['activity', 'actual_mean', 'actual_std', 'sample_count']])\n",
        "\n",
        "# Merge with participant characteristics for clustering\n",
        "merged_df = pd.merge(acc_df, participants_df, on='participant', how='inner')\n",
        "\n",
        "if merged_df.empty:\n",
        "    print(\"Error: No matching participants found after merging.\")\n",
        "    exit(1)\n",
        "\n",
        "# Debug: Print original data size\n",
        "print(\"Original data size:\", len(merged_df))\n",
        "\n",
        "# Initialize 5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "results_list = []\n",
        "\n",
        "# Iterate over folds\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(merged_df), 1):\n",
        "    print(f\"Processing Fold {fold}\")\n",
        "    train_df = merged_df.iloc[train_index].copy()\n",
        "    test_df = merged_df.iloc[test_index].copy()\n",
        "    print(f\"Training set size: {len(train_df)}, Test set size: {len(test_df)}\")\n",
        "\n",
        "    # Prepare data for clustering on training set, including magnitude\n",
        "    X_cluster_train = train_df[['age', 'gender', 'height', 'weight', 'magnitude', 'activity']]\n",
        "    scaler = RobustScaler()\n",
        "    X_numeric_train = scaler.fit_transform(X_cluster_train[['age', 'gender', 'height', 'weight', 'magnitude']])\n",
        "    X_activity_train = pd.get_dummies(X_cluster_train['activity'], prefix='activity')\n",
        "    X_scaled_train = np.hstack([X_numeric_train, X_activity_train])\n",
        "\n",
        "    # Determine optimal number of clusters using the elbow method on training set\n",
        "    wcss = []\n",
        "    max_clusters = 11\n",
        "    for i in range(2, max_clusters + 1):\n",
        "        kmeans = KMeans(n_clusters=i, random_state=42)\n",
        "        kmeans.fit(X_scaled_train)\n",
        "        wcss.append(kmeans.inertia_)\n",
        "\n",
        "    # Plot the elbow curve for this fold (optional, can be disabled for efficiency)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(range(2, max_clusters + 1), wcss, marker='o')\n",
        "    plt.title(f'Elbow Method for Optimal Number of Clusters - Fold {fold}')\n",
        "    plt.xlabel('Number of Clusters')\n",
        "    plt.ylabel('WCSS')\n",
        "    plt.savefig(f'/content/drive/My Drive/ColabNotebooks/elbow_curve_gnn_further_fold_{fold}.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Choose the optimal number of clusters\n",
        "    optimal_clusters = 11  # Placeholder, adjust based on elbow curve\n",
        "    for i in range(2, len(wcss) - 1):\n",
        "        if (wcss[i-1] - wcss[i]) / (wcss[i] - wcss[i+1]) < 0.5:\n",
        "            optimal_clusters = i + 2\n",
        "            break\n",
        "    print(f\"Optimal number of clusters for Fold {fold}: {optimal_clusters}\")\n",
        "\n",
        "    # Perform K-means clustering with optimal number of clusters on training set\n",
        "    kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
        "    train_cluster_labels = kmeans.fit_predict(X_scaled_train)\n",
        "\n",
        "    # Assign clusters to test set using the trained K-means model\n",
        "    X_cluster_test = test_df[['age', 'gender', 'height', 'weight', 'magnitude', 'activity']]\n",
        "    X_numeric_test = scaler.transform(X_cluster_test[['age', 'gender', 'height', 'weight', 'magnitude']])\n",
        "    X_activity_test = pd.get_dummies(X_cluster_test['activity'], prefix='activity')\n",
        "    # Align columns between train and test activity dummies\n",
        "    X_activity_test = X_activity_test.reindex(columns=X_activity_train.columns, fill_value=0)\n",
        "    X_scaled_test = np.hstack([X_numeric_test, X_activity_test])\n",
        "    test_cluster_labels = kmeans.predict(X_scaled_test)\n",
        "\n",
        "    # Add cluster labels to train and test dataframes\n",
        "    train_df['cluster'] = train_cluster_labels\n",
        "    test_df['cluster'] = test_cluster_labels\n",
        "\n",
        "    # Combine train and test dataframes for this fold\n",
        "    fold_df = pd.concat([train_df, test_df], axis=0)\n",
        "\n",
        "    # Assign cluster mean and std for Z-score calculation using K-means clusters\n",
        "    cluster_means = train_df.groupby('cluster')['magnitude'].mean().to_dict()\n",
        "    cluster_stds = train_df.groupby('cluster')['magnitude'].std().to_dict()\n",
        "    fold_df['cluster_mu'] = fold_df['cluster'].map(cluster_means)\n",
        "    fold_df['cluster_sigma'] = fold_df['cluster'].map(cluster_stds).fillna(global_activity_std)\n",
        "\n",
        "    # Compute Z-scores using cluster-based statistics\n",
        "    fold_df['Z_score'] = (fold_df['magnitude'] - fold_df['cluster_mu']) / fold_df['cluster_sigma'].replace(0, np.nan)\n",
        "    fold_df['traditional_Z_score'] = (fold_df['magnitude'] - global_magnitude_mean) / global_magnitude_std\n",
        "\n",
        "    # Add global mean and std to output\n",
        "    fold_df['global_magnitude_mean'] = global_magnitude_mean\n",
        "    fold_df['global_magnitude_std'] = global_magnitude_std\n",
        "\n",
        "    # Apply activity-specific plausible ranges\n",
        "    fold_df['activity'] = fold_df['activity'].str.lower()\n",
        "    default_min_plausible = 0\n",
        "    default_max_plausible = 10\n",
        "    fold_df['min_plausible'] = fold_df['activity'].map(lambda x: activity_ranges.get(x, {'min': default_min_plausible})['min'])\n",
        "    fold_df['max_plausible'] = fold_df['activity'].map(lambda x: activity_ranges.get(x, {'max': default_max_plausible})['max'])\n",
        "\n",
        "    # Determine if observations are outside plausible range\n",
        "    fold_df['outside_plausible'] = (fold_df['magnitude'] < fold_df['min_plausible']) | (fold_df['magnitude'] > fold_df['max_plausible'])\n",
        "\n",
        "    # Determine anomaly\n",
        "    threshold = 2\n",
        "    fold_df['is_anomaly'] = np.abs(fold_df['Z_score']) > threshold\n",
        "    fold_df['is_anomaly_traditional'] = np.abs(fold_df['traditional_Z_score']) > threshold\n",
        "\n",
        "    # Label noise\n",
        "    fold_df['is_noise'] = fold_df['is_anomaly'] & fold_df['outside_plausible']\n",
        "    fold_df['is_noise_traditional'] = fold_df['is_anomaly_traditional'] & fold_df['outside_plausible']\n",
        "\n",
        "    # Round numerical columns in fold_df to 2 decimal places\n",
        "    numerical_cols = fold_df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    fold_df[numerical_cols] = fold_df[numerical_cols].round(2)\n",
        "\n",
        "    # Function to introduce Generalized Normal noise with adjusted beta\n",
        "    def introduce_gnn_noise(df, beta=1.5, scale=0.1, noise_fraction=0.05):\n",
        "        noisy_df = df.copy()\n",
        "        mask = np.random.rand(len(noisy_df)) < noise_fraction\n",
        "        noise = gennorm.rvs(beta=beta, loc=0, scale=scale, size=len(noisy_df))\n",
        "        noisy_df['magnitude'] = noisy_df['magnitude'] + noise * mask\n",
        "        noisy_df['is_true_noise'] = mask.astype(int)  # Ground truth: 1 for noisy, 0 for normal\n",
        "        return noisy_df\n",
        "\n",
        "    # List of noise fractions to test\n",
        "    noise_fractions = [0.02, 0.05, 0.10, 0.20]\n",
        "\n",
        "    # Iterate over noise levels\n",
        "    for noise_fraction in noise_fractions:\n",
        "        print(f\"Processing noise fraction: {noise_fraction*100}% in Fold {fold}\")\n",
        "        # Introduce noise to the dataset with adjusted beta\n",
        "        noisy_df = introduce_gnn_noise(fold_df, beta=1.5, scale=2 * global_magnitude_std, noise_fraction=noise_fraction)\n",
        "\n",
        "        # Apply anomaly detection - Hybrid method\n",
        "        noisy_df['Z_score'] = (noisy_df['magnitude'] - noisy_df['cluster_mu']) / noisy_df['cluster_sigma'].replace(0, np.nan)\n",
        "        noisy_df['is_anomaly'] = np.abs(noisy_df['Z_score']) > threshold\n",
        "        noisy_df['outside_plausible'] = (noisy_df['magnitude'] < noisy_df['min_plausible']) | (noisy_df['magnitude'] > noisy_df['max_plausible'])\n",
        "        noisy_df['is_noise'] = noisy_df['is_anomaly'] & noisy_df['outside_plausible']\n",
        "\n",
        "        # Apply anomaly detection - Traditional method\n",
        "        noisy_df['traditional_Z_score'] = (noisy_df['magnitude'] - global_magnitude_mean) / global_magnitude_std\n",
        "        noisy_df['is_anomaly_traditional'] = np.abs(noisy_df['traditional_Z_score']) > threshold\n",
        "        noisy_df['is_noise_traditional'] = noisy_df['is_anomaly_traditional'] & noisy_df['outside_plausible']\n",
        "\n",
        "        # Evaluate performance\n",
        "        y_true = noisy_df['is_true_noise']\n",
        "        y_pred_hybrid = noisy_df['is_noise'].astype(int)\n",
        "        y_pred_traditional = noisy_df['is_noise_traditional'].astype(int)\n",
        "\n",
        "        precision_hybrid = precision_score(y_true, y_pred_hybrid)\n",
        "        recall_hybrid = recall_score(y_true, y_pred_hybrid)\n",
        "        f1_hybrid = f1_score(y_true, y_pred_hybrid)\n",
        "\n",
        "        precision_traditional = precision_score(y_true, y_pred_traditional)\n",
        "        recall_traditional = recall_score(y_true, y_pred_traditional)\n",
        "        f1_traditional = f1_score(y_true, y_pred_traditional)\n",
        "\n",
        "        # Calculate percentage of noise detected\n",
        "        total_noise_points = y_true.sum()\n",
        "        hybrid_detected = y_pred_hybrid[y_true == 1].sum()\n",
        "        traditional_detected = y_pred_traditional[y_true == 1].sum()\n",
        "        hybrid_noise_percentage = (hybrid_detected / total_noise_points * 100) if total_noise_points > 0 else 0\n",
        "        traditional_noise_percentage = (traditional_detected / total_noise_points * 100) if total_noise_points > 0 else 0\n",
        "\n",
        "        # Store results for this noise level and fold\n",
        "        results_list.append({\n",
        "            'Fold': fold,\n",
        "            'Algorithm': 'K-means',\n",
        "            'Noise Fraction (%)': noise_fraction * 100,\n",
        "            'Method': 'Hybrid (Cluster-based)',\n",
        "            'Precision': precision_hybrid,\n",
        "            'Recall': recall_hybrid,\n",
        "            'F1 Score': f1_hybrid,\n",
        "            'Noise Detected (%)': hybrid_noise_percentage\n",
        "        })\n",
        "        results_list.append({\n",
        "            'Fold': fold,\n",
        "            'Algorithm': 'K-means',\n",
        "            'Noise Fraction (%)': noise_fraction * 100,\n",
        "            'Method': 'Traditional (Global)',\n",
        "            'Precision': precision_traditional,\n",
        "            'Recall': recall_traditional,\n",
        "            'F1 Score': f1_traditional,\n",
        "            'Noise Detected (%)': traditional_noise_percentage\n",
        "        })\n",
        "\n",
        "# Create consolidated results table\n",
        "results_df = pd.DataFrame(results_list)\n",
        "print(\"\\nConsolidated Evaluation Results:\")\n",
        "print(results_df.groupby(['Noise Fraction (%)', 'Method']).agg({\n",
        "    'Precision': 'mean',\n",
        "    'Recall': 'mean',\n",
        "    'F1 Score': 'mean',\n",
        "    'Noise Detected (%)': 'mean'\n",
        "}).reset_index())\n",
        "\n",
        "# Save noisy dataset and results for the last fold\n",
        "try:\n",
        "    noisy_df.to_csv('/content/drive/My Drive/ColabNotebooks/noisy_results_kmeans_gnn_further.csv', index=False)\n",
        "    print(f\"Noisy dataset saved to '/content/drive/My Drive/ColabNotebooks/noisy_results_kmeans_gnn_further.csv'.\")\n",
        "    results_df.to_csv('/content/drive/My Drive/ColabNotebooks/evaluation_results_kmeans_gnn_further.csv', index=False)\n",
        "    print(f\"Evaluation results saved to '/content/drive/My Drive/ColabNotebooks/evaluation_results_kmeans_gnn_further.csv'.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving files: {e}\")\n",
        "\n",
        "# Debug: Print summary for the last noise level of the last fold\n",
        "print(\"\\nZ-score stats (noisy dataset, last noise level of last fold):\\n\", noisy_df[['Z_score', 'traditional_Z_score']].describe())\n",
        "print(\"Noise detection summary (hybrid, noisy dataset, last noise level of last fold):\\n\", noisy_df['is_noise'].value_counts())\n",
        "print(\"Noise detection summary (traditional, noisy dataset, last noise level of last fold):\\n\", noisy_df['is_noise_traditional'].value_counts())\n",
        "print(f\"Total noise points introduced (last noise level of last fold): {total_noise_points}\")\n",
        "print(f\"Hybrid method detected (last noise level of last fold): {hybrid_detected} ({hybrid_noise_percentage:.2f}%)\")\n",
        "print(f\"Traditional method detected (last noise level of last fold): {traditional_detected} ({traditional_noise_percentage:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxKVeoK8taNj",
        "outputId": "89a304aa-87c4-4cab-dc22-cc691ee18ed9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global magnitude stats: Mean = 0.753240, Std = 0.638734\n",
            "Per-activity magnitude stats:\n",
            "   activity  actual_mean  actual_std  sample_count\n",
            "0      dws     0.575685    0.426152        131856\n",
            "1      jog     1.445474    0.905656        134231\n",
            "2      ups     0.447230    0.337824        157285\n",
            "3      wlk     0.691151    0.471883        344288\n",
            "Original data size: 767660\n",
            "Processing Fold 1\n",
            "Training set size: 614128, Test set size: 153532\n",
            "Optimal number of clusters for Fold 1: 7\n",
            "Processing noise fraction: 2.0% in Fold 1\n",
            "Processing noise fraction: 5.0% in Fold 1\n",
            "Processing noise fraction: 10.0% in Fold 1\n",
            "Processing noise fraction: 20.0% in Fold 1\n",
            "Processing Fold 2\n",
            "Training set size: 614128, Test set size: 153532\n",
            "Optimal number of clusters for Fold 2: 11\n",
            "Processing noise fraction: 2.0% in Fold 2\n",
            "Processing noise fraction: 5.0% in Fold 2\n",
            "Processing noise fraction: 10.0% in Fold 2\n",
            "Processing noise fraction: 20.0% in Fold 2\n",
            "Processing Fold 3\n",
            "Training set size: 614128, Test set size: 153532\n",
            "Optimal number of clusters for Fold 3: 11\n",
            "Processing noise fraction: 2.0% in Fold 3\n",
            "Processing noise fraction: 5.0% in Fold 3\n",
            "Processing noise fraction: 10.0% in Fold 3\n",
            "Processing noise fraction: 20.0% in Fold 3\n",
            "Processing Fold 4\n",
            "Training set size: 614128, Test set size: 153532\n",
            "Optimal number of clusters for Fold 4: 11\n",
            "Processing noise fraction: 2.0% in Fold 4\n",
            "Processing noise fraction: 5.0% in Fold 4\n",
            "Processing noise fraction: 10.0% in Fold 4\n",
            "Processing noise fraction: 20.0% in Fold 4\n",
            "Processing Fold 5\n",
            "Training set size: 614128, Test set size: 153532\n",
            "Optimal number of clusters for Fold 5: 11\n",
            "Processing noise fraction: 2.0% in Fold 5\n",
            "Processing noise fraction: 5.0% in Fold 5\n",
            "Processing noise fraction: 10.0% in Fold 5\n",
            "Processing noise fraction: 20.0% in Fold 5\n",
            "\n",
            "Consolidated Evaluation Results:\n",
            "   Noise Fraction (%)                  Method  Precision    Recall  F1 Score  \\\n",
            "0                 2.0  Hybrid (Cluster-based)   0.717061  0.333579  0.454795   \n",
            "1                 2.0    Traditional (Global)   0.237926  0.224180  0.230846   \n",
            "2                 5.0  Hybrid (Cluster-based)   0.866310  0.334227  0.482233   \n",
            "3                 5.0    Traditional (Global)   0.446823  0.225063  0.299346   \n",
            "4                10.0  Hybrid (Cluster-based)   0.931294  0.333065  0.490609   \n",
            "5                10.0    Traditional (Global)   0.628924  0.223521  0.329821   \n",
            "6                20.0  Hybrid (Cluster-based)   0.968277  0.333134  0.495705   \n",
            "7                20.0    Traditional (Global)   0.792461  0.223269  0.348383   \n",
            "\n",
            "   Noise Detected (%)  \n",
            "0           33.357866  \n",
            "1           22.417995  \n",
            "2           33.422717  \n",
            "3           22.506288  \n",
            "4           33.306483  \n",
            "5           22.352103  \n",
            "6           33.313433  \n",
            "7           22.326914  \n",
            "Noisy dataset saved to '/content/drive/My Drive/ColabNotebooks/noisy_results_kmeans_gnn_further.csv'.\n",
            "Evaluation results saved to '/content/drive/My Drive/ColabNotebooks/evaluation_results_kmeans_gnn_further.csv'.\n",
            "\n",
            "Z-score stats (noisy dataset, last noise level of last fold):\n",
            "              Z_score  traditional_Z_score\n",
            "count  767660.000000        767660.000000\n",
            "mean        0.005300            -0.000467\n",
            "std         2.027263             1.259707\n",
            "min       -29.655925           -10.732942\n",
            "25%        -0.846154            -0.678279\n",
            "50%        -0.115385            -0.271224\n",
            "75%         0.800000             0.417638\n",
            "max        23.988495            14.852893\n",
            "Noise detection summary (hybrid, noisy dataset, last noise level of last fold):\n",
            " is_noise\n",
            "False    715411\n",
            "True      52249\n",
            "Name: count, dtype: int64\n",
            "Noise detection summary (traditional, noisy dataset, last noise level of last fold):\n",
            " is_noise_traditional\n",
            "False    724455\n",
            "True      43205\n",
            "Name: count, dtype: int64\n",
            "Total noise points introduced (last noise level of last fold): 153692\n",
            "Hybrid method detected (last noise level of last fold): 50996 (33.18%)\n",
            "Traditional method detected (last noise level of last fold): 34230 (22.27%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdflib import Graph\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from scipy.stats import gennorm\n",
        "import itertools\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Paths to sensor reading csv file data and knowledge graph\n",
        "data_path = \"/content/drive/My Drive/ColabNotebooks/motion_sensor_readings.csv\"\n",
        "kg_path = \"/content/drive/My Drive/ColabNotebooks/motion_sense_ssn_kg.ttl\"\n",
        "\n",
        "# Load knowledge graph\n",
        "g = Graph()\n",
        "try:\n",
        "    g.parse(kg_path, format='turtle')\n",
        "except Exception as e:\n",
        "    print(f\"Error parsing knowledge graph: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "# Query for participant characteristics\n",
        "query = \"\"\"\n",
        "PREFIX ms: <http://example.org/motion-sense#>\n",
        "SELECT ?p ?code ?age ?gender ?height ?weight\n",
        "WHERE {\n",
        "    ?p a ms:Participant ;\n",
        "       ms:hasCode ?code ;\n",
        "       ms:hasAge ?age ;\n",
        "       ms:hasGender ?gender ;\n",
        "       ms:hasHeightCm ?height ;\n",
        "       ms:hasWeightKg ?weight .\n",
        "}\n",
        "\"\"\"\n",
        "results = g.query(query)\n",
        "participants = []\n",
        "for row in results:\n",
        "    participants.append({\n",
        "        'participant': str(row.code).strip().upper(),\n",
        "        'age': int(row.age),\n",
        "        'gender': int(row.gender),\n",
        "        'height': float(row.height),\n",
        "        'weight': float(row.weight)\n",
        "    })\n",
        "participants_df = pd.DataFrame(participants)\n",
        "\n",
        "if participants_df.empty:\n",
        "    print(\"Error: No participants found in knowledge graph.\")\n",
        "    exit(1)\n",
        "\n",
        "# Query for activity plausible ranges\n",
        "query_ranges = \"\"\"\n",
        "PREFIX activity: <http://example.org/activity-recognition#>\n",
        "SELECT ?activityCode ?min ?max\n",
        "WHERE {\n",
        "    ?act a activity:Activity ;\n",
        "         activity:hasActivityCode ?activityCode ;\n",
        "         activity:hasMinAcceleration ?min ;\n",
        "         activity:hasMaxAcceleration ?max .\n",
        "}\n",
        "\"\"\"\n",
        "results_ranges = g.query(query_ranges)\n",
        "activity_ranges = {}\n",
        "for row in results_ranges:\n",
        "    activity_code = str(row.activityCode).strip().lower()\n",
        "    activity_ranges[activity_code] = {\n",
        "        'min': float(row.min),\n",
        "        'max': float(row.max)\n",
        "    }\n",
        "\n",
        "if not activity_ranges:\n",
        "    print(\"Error: No activity ranges found in knowledge graph.\")\n",
        "    exit(1)\n",
        "\n",
        "# Load sensor readings csv file data\n",
        "try:\n",
        "    df = pd.read_csv(data_path)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading sensor data: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "# Parse sensor_id with validation\n",
        "def parse_sensor_id(sid):\n",
        "    parts = sid.split('_')\n",
        "    if len(parts) >= 5:\n",
        "        return parts[0].strip().upper(), parts[3], parts[4]\n",
        "    return None, None, None\n",
        "\n",
        "df['participant'], df['activity'], df['sensor_type'] = zip(*df['sensor_id'].apply(parse_sensor_id))\n",
        "df = df.dropna(subset=['participant'])\n",
        "\n",
        "# Filter for accelerometer data\n",
        "df = df[(df['sensor_type'] == 'Accelerometer') &\n",
        "        (df['property'].isin(['UserAccelerationX', 'UserAccelerationY', 'UserAccelerationZ']))]\n",
        "\n",
        "# Convert measurement to numeric, drop invalid entries\n",
        "df['measurement'] = pd.to_numeric(df['measurement'], errors='coerce')\n",
        "df = df.dropna(subset=['measurement'])\n",
        "\n",
        "if df.empty:\n",
        "    print(\"Error: No valid accelerometer data after cleaning.\")\n",
        "    exit(1)\n",
        "\n",
        "# Pivot to get X, Y, Z\n",
        "acc_df = df.pivot_table(index=['timestamp', 'sensor_id', 'participant', 'activity'],\n",
        "                        columns='property', values='measurement', aggfunc='first').reset_index()\n",
        "\n",
        "# Drop rows with missing or invalid acceleration components\n",
        "acc_df = acc_df.dropna(subset=['UserAccelerationX', 'UserAccelerationY', 'UserAccelerationZ'])\n",
        "for col in ['UserAccelerationX', 'UserAccelerationY', 'UserAccelerationZ']:\n",
        "    acc_df[col] = pd.to_numeric(acc_df[col], errors='coerce')\n",
        "acc_df = acc_df.dropna(subset=['UserAccelerationX', 'UserAccelerationY', 'UserAccelerationZ'])\n",
        "\n",
        "if acc_df.empty:\n",
        "    print(\"Error: No valid data after pivot and cleaning.\")\n",
        "    exit(1)\n",
        "\n",
        "# Compute magnitude\n",
        "acc_df['magnitude'] = np.sqrt(acc_df['UserAccelerationX']**2 +\n",
        "                              acc_df['UserAccelerationY']**2 +\n",
        "                              acc_df['UserAccelerationZ']**2)\n",
        "\n",
        "# Compute global mean and std for magnitude (for traditional Z-score)\n",
        "global_magnitude_mean = acc_df['magnitude'].mean()\n",
        "global_magnitude_std = acc_df['magnitude'].std()\n",
        "print(f\"Global magnitude stats (after outlier removal): Mean = {global_magnitude_mean:.6f}, Std = {global_magnitude_std:.6f}\")\n",
        "\n",
        "# Compute per-activity stats for reference on cleaned data\n",
        "activity_stats_df = acc_df.groupby('activity')['magnitude'].agg(['mean', 'std', 'count']).reset_index()\n",
        "activity_stats_df.columns = ['activity', 'actual_mean', 'actual_std', 'sample_count']\n",
        "\n",
        "# Ensure sufficient samples and smooth std\n",
        "activity_stats_df = activity_stats_df[activity_stats_df['sample_count'] >= 100]\n",
        "global_activity_std = activity_stats_df['actual_std'].mean()\n",
        "activity_stats_df['actual_std'] = activity_stats_df['actual_std'].apply(lambda x: max(x, global_activity_std * 0.1))\n",
        "\n",
        "# Debug: Print per-activity stats\n",
        "print(\"Per-activity magnitude stats:\\n\", activity_stats_df[['activity', 'actual_mean', 'actual_std', 'sample_count']])\n",
        "\n",
        "# Merge with participant characteristics\n",
        "merged_df = pd.merge(acc_df, participants_df, on='participant', how='inner')\n",
        "\n",
        "if merged_df.empty:\n",
        "    print(\"Error: No matching participants found after merging.\")\n",
        "    exit(1)\n",
        "\n",
        "# Debug: Print original data size\n",
        "print(\"Original data size:\", len(merged_df))\n",
        "\n",
        "# Split into training and test sets\n",
        "train_df, test_df = train_test_split(merged_df, test_size=0.2, random_state=42)\n",
        "print(f\"Training set size: {len(train_df)}, Test set size: {len(test_df)}\")\n",
        "\n",
        "# Define feature sets to test\n",
        "semantic_features = ['age', 'gender', 'height', 'weight', 'activity']\n",
        "feature_combinations = []\n",
        "# Include magnitude-only as baseline\n",
        "feature_combinations.append(['magnitude'])\n",
        "# Test magnitude with each semantic feature\n",
        "for r in range(1, len(semantic_features) + 1):\n",
        "    for combo in itertools.combinations(semantic_features, r):\n",
        "        feature_combinations.append(['magnitude'] + list(combo))\n",
        "\n",
        "# Function to preprocess features for clustering\n",
        "def preprocess_features(df, features, activity_train=None):\n",
        "    numerical_features = [f for f in features if f in ['magnitude', 'age', 'height', 'weight']]\n",
        "    categorical_features = [f for f in features if f in ['gender', 'activity']]\n",
        "\n",
        "    scaler = RobustScaler()\n",
        "    X_numeric = scaler.fit_transform(df[numerical_features]) if numerical_features else np.array([])\n",
        "\n",
        "    X_categorical = []\n",
        "    if 'gender' in categorical_features:\n",
        "        X_gender = df['gender'].values.reshape(-1, 1)\n",
        "        X_categorical.append(X_gender)\n",
        "\n",
        "    if 'activity' in categorical_features:\n",
        "        X_activity = pd.get_dummies(df['activity'], prefix='activity')\n",
        "        if activity_train is not None:\n",
        "            X_activity = X_activity.reindex(columns=activity_train.columns, fill_value=0)\n",
        "        else:\n",
        "            activity_train = X_activity\n",
        "        X_categorical.append(X_activity.values)\n",
        "\n",
        "    if X_categorical:\n",
        "        X_cat = np.hstack(X_categorical) if len(X_categorical) > 1 else X_categorical[0]\n",
        "        X_scaled = np.hstack([X_numeric, X_cat]) if len(X_numeric) > 0 else X_cat\n",
        "    else:\n",
        "        X_scaled = X_numeric\n",
        "\n",
        "    return X_scaled, scaler, activity_train\n",
        "\n",
        "# Function to introduce GNN noise\n",
        "def introduce_gnn_noise(df, beta=1.5, scale=0.1, noise_fraction=0.05):\n",
        "    noisy_df = df.copy()\n",
        "    mask = np.random.rand(len(noisy_df)) < noise_fraction\n",
        "    noise = gennorm.rvs(beta=beta, loc=0, scale=scale, size=len(noisy_df))\n",
        "    noisy_df['magnitude'] = noisy_df['magnitude'] + noise * mask\n",
        "    noisy_df['is_true_noise'] = mask.astype(int)\n",
        "    return noisy_df\n",
        "\n",
        "# Evaluate each feature combination\n",
        "results_list = []\n",
        "noise_fraction = 0.2  # Test at 20% noise level\n",
        "max_clusters = 11\n",
        "threshold = 2\n",
        "\n",
        "for features in feature_combinations:\n",
        "    print(f\"\\nTesting feature combination: {features}\")\n",
        "\n",
        "    # Cross-validation setup\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    cv_f1_scores = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(merged_df)):\n",
        "        train_df = merged_df.iloc[train_idx]\n",
        "        val_df = merged_df.iloc[val_idx]\n",
        "\n",
        "        # Preprocess training data\n",
        "        X_scaled_train, scaler, activity_train = preprocess_features(train_df, features)\n",
        "\n",
        "        # Elbow method to determine optimal clusters\n",
        "        wcss = []\n",
        "        for i in range(2, max_clusters + 1):\n",
        "            kmeans = KMeans(n_clusters=i, random_state=42)\n",
        "            kmeans.fit(X_scaled_train)\n",
        "            wcss.append(kmeans.inertia_)\n",
        "\n",
        "        optimal_clusters = 11  # Default, adjust based on elbow method\n",
        "        for i in range(2, len(wcss) - 1):\n",
        "            if (wcss[i-1] - wcss[i]) / (wcss[i] - wcss[i+1]) < 0.5:\n",
        "                optimal_clusters = i + 2\n",
        "                break\n",
        "\n",
        "        # Perform K-means clustering\n",
        "        kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
        "        train_cluster_labels = kmeans.fit_predict(X_scaled_train)\n",
        "\n",
        "        # Assign clusters to validation set\n",
        "        X_scaled_val, _, _ = preprocess_features(val_df, features, activity_train)\n",
        "        val_cluster_labels = kmeans.predict(X_scaled_val)\n",
        "\n",
        "        train_df = train_df.copy()\n",
        "        val_df = val_df.copy()\n",
        "        train_df['cluster'] = train_cluster_labels\n",
        "        val_df['cluster'] = val_cluster_labels\n",
        "\n",
        "        # Combine for anomaly detection\n",
        "        acc_df = pd.concat([train_df, val_df], axis=0)\n",
        "\n",
        "        # Compute cluster stats\n",
        "        cluster_means = train_df.groupby('cluster')['magnitude'].mean().to_dict()\n",
        "        cluster_stds = train_df.groupby('cluster')['magnitude'].std().to_dict()\n",
        "        acc_df['cluster_mu'] = acc_df['cluster'].map(cluster_means)\n",
        "        acc_df['cluster_sigma'] = acc_df['cluster'].map(cluster_stds).fillna(global_activity_std)\n",
        "\n",
        "        # Compute Z-scores\n",
        "        acc_df['Z_score'] = (acc_df['magnitude'] - acc_df['cluster_mu']) / acc_df['cluster_sigma'].replace(0, np.nan)\n",
        "        acc_df['traditional_Z_score'] = (acc_df['magnitude'] - global_magnitude_mean) / global_magnitude_std\n",
        "\n",
        "        # Apply activity-specific plausible ranges\n",
        "        acc_df['activity'] = acc_df['activity'].str.lower()\n",
        "        default_min_plausible = 0\n",
        "        default_max_plausible = 10\n",
        "        acc_df['min_plausible'] = acc_df['activity'].map(lambda x: activity_ranges.get(x, {'min': default_min_plausible})['min'])\n",
        "        acc_df['max_plausible'] = acc_df['activity'].map(lambda x: activity_ranges.get(x, {'max': default_max_plausible})['max'])\n",
        "\n",
        "        acc_df['outside_plausible'] = (acc_df['magnitude'] < acc_df['min_plausible']) | (acc_df['magnitude'] > acc_df['max_plausible'])\n",
        "\n",
        "        # Introduce noise\n",
        "        noisy_df = introduce_gnn_noise(acc_df, beta=1.5, scale=2 * global_magnitude_std, noise_fraction=noise_fraction)\n",
        "\n",
        "        # Apply anomaly detection - Hybrid method\n",
        "        noisy_df['Z_score'] = (noisy_df['magnitude'] - noisy_df['cluster_mu']) / noisy_df['cluster_sigma'].replace(0, np.nan)\n",
        "        noisy_df['is_anomaly'] = np.abs(noisy_df['Z_score']) > threshold\n",
        "        noisy_df['outside_plausible'] = (noisy_df['magnitude'] < noisy_df['min_plausible']) | (noisy_df['magnitude'] > noisy_df['max_plausible'])\n",
        "        noisy_df['is_noise'] = noisy_df['is_anomaly'] & noisy_df['outside_plausible']\n",
        "\n",
        "        # Evaluate performance\n",
        "        y_true = noisy_df['is_true_noise']\n",
        "        y_pred_hybrid = noisy_df['is_noise'].astype(int)\n",
        "\n",
        "        precision_hybrid = precision_score(y_true, y_pred_hybrid, zero_division=0)\n",
        "        recall_hybrid = recall_score(y_true, y_pred_hybrid, zero_division=0)\n",
        "        f1_hybrid = f1_score(y_true, y_pred_hybrid, zero_division=0)\n",
        "\n",
        "        total_noise_points = y_true.sum()\n",
        "        hybrid_detected = y_pred_hybrid[y_true == 1].sum()\n",
        "        hybrid_noise_percentage = (hybrid_detected / total_noise_points * 100) if total_noise_points > 0 else 0\n",
        "\n",
        "        # Print results for this fold\n",
        "        print(f\"Fold {fold + 1} Results - Features: {features}\")\n",
        "        print(f\"  Precision: {precision_hybrid:.6f}\")\n",
        "        print(f\"  Recall: {recall_hybrid:.6f}\")\n",
        "        print(f\"  F1 Score: {f1_hybrid:.6f}\")\n",
        "        print(f\"  Noise Detected (%): {hybrid_noise_percentage:.6f}\")\n",
        "\n",
        "        cv_f1_scores.append(f1_hybrid)\n",
        "\n",
        "    # Average F1-score across folds\n",
        "    avg_f1_score = np.mean(cv_f1_scores)\n",
        "\n",
        "    # Store results for this feature combination\n",
        "    results_list.append({\n",
        "        'Features': ', '.join(features),\n",
        "        'Avg F1 Score': avg_f1_score,\n",
        "        'Precision': precision_hybrid,  # From last fold\n",
        "        'Recall': recall_hybrid,\n",
        "        'Noise Detected (%)': hybrid_noise_percentage\n",
        "    })\n",
        "\n",
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame(results_list)\n",
        "results_df = results_df.sort_values(by='Avg F1 Score', ascending=False)\n",
        "print(\"\\nFeature Selection Results (sorted by Avg F1 Score):\")\n",
        "print(results_df)\n",
        "\n",
        "# Save results\n",
        "try:\n",
        "    results_df.to_csv('/content/drive/My Drive/ColabNotebooks/feature_selection_results.csv', index=False)\n",
        "    print(f\"Feature selection results saved to '/content/drive/My Drive/ColabNotebooks/feature_selection_results.csv'.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving files: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDnjvNjh0nFU",
        "outputId": "b5b1c4eb-d623-48bf-a36d-86257a4b3ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global magnitude stats (after outlier removal): Mean = 0.753240, Std = 0.638734\n",
            "Per-activity magnitude stats:\n",
            "   activity  actual_mean  actual_std  sample_count\n",
            "0      dws     0.575685    0.426152        131856\n",
            "1      jog     1.445474    0.905656        134231\n",
            "2      ups     0.447230    0.337824        157285\n",
            "3      wlk     0.691151    0.471883        344288\n",
            "Original data size: 767660\n",
            "Training set size: 614128, Test set size: 153532\n",
            "\n",
            "Testing feature combination: ['magnitude']\n",
            "Fold 1 Results - Features: ['magnitude']\n",
            "  Precision: 0.995267\n",
            "  Recall: 0.345343\n",
            "  F1 Score: 0.512765\n",
            "  Noise Detected (%): 34.534349\n",
            "Fold 2 Results - Features: ['magnitude']\n",
            "  Precision: 0.994994\n",
            "  Recall: 0.345821\n",
            "  F1 Score: 0.513255\n",
            "  Noise Detected (%): 34.582099\n",
            "Fold 3 Results - Features: ['magnitude']\n",
            "  Precision: 0.996198\n",
            "  Recall: 0.344464\n",
            "  F1 Score: 0.511918\n",
            "  Noise Detected (%): 34.446406\n",
            "Fold 4 Results - Features: ['magnitude']\n",
            "  Precision: 0.994923\n",
            "  Recall: 0.343369\n",
            "  F1 Score: 0.510540\n",
            "  Noise Detected (%): 34.336933\n",
            "Fold 5 Results - Features: ['magnitude']\n",
            "  Precision: 0.995984\n",
            "  Recall: 0.347615\n",
            "  F1 Score: 0.515360\n",
            "  Noise Detected (%): 34.761492\n",
            "\n",
            "Testing feature combination: ['magnitude', 'age']\n",
            "Fold 1 Results - Features: ['magnitude', 'age']\n",
            "  Precision: 0.978770\n",
            "  Recall: 0.341679\n",
            "  F1 Score: 0.506532\n",
            "  Noise Detected (%): 34.167867\n",
            "Fold 2 Results - Features: ['magnitude', 'age']\n",
            "  Precision: 0.979266\n",
            "  Recall: 0.341115\n",
            "  F1 Score: 0.505978\n",
            "  Noise Detected (%): 34.111461\n",
            "Fold 3 Results - Features: ['magnitude', 'age']\n",
            "  Precision: 0.979101\n",
            "  Recall: 0.339183\n",
            "  F1 Score: 0.503828\n",
            "  Noise Detected (%): 33.918296\n",
            "Fold 4 Results - Features: ['magnitude', 'age']\n",
            "  Precision: 0.978113\n",
            "  Recall: 0.339060\n",
            "  F1 Score: 0.503562\n",
            "  Noise Detected (%): 33.905999\n",
            "Fold 5 Results - Features: ['magnitude', 'age']\n",
            "  Precision: 0.981582\n",
            "  Recall: 0.341153\n",
            "  F1 Score: 0.506330\n",
            "  Noise Detected (%): 34.115338\n",
            "\n",
            "Testing feature combination: ['magnitude', 'gender']\n",
            "Fold 1 Results - Features: ['magnitude', 'gender']\n",
            "  Precision: 0.993036\n",
            "  Recall: 0.345197\n",
            "  F1 Score: 0.512306\n",
            "  Noise Detected (%): 34.519661\n",
            "Fold 2 Results - Features: ['magnitude', 'gender']\n",
            "  Precision: 0.988892\n",
            "  Recall: 0.343899\n",
            "  F1 Score: 0.510326\n",
            "  Noise Detected (%): 34.389875\n",
            "Fold 3 Results - Features: ['magnitude', 'gender']\n",
            "  Precision: 0.989711\n",
            "  Recall: 0.344944\n",
            "  F1 Score: 0.511585\n",
            "  Noise Detected (%): 34.494406\n",
            "Fold 4 Results - Features: ['magnitude', 'gender']\n",
            "  Precision: 0.988876\n",
            "  Recall: 0.342238\n",
            "  F1 Score: 0.508493\n",
            "  Noise Detected (%): 34.223818\n",
            "Fold 5 Results - Features: ['magnitude', 'gender']\n",
            "  Precision: 0.989384\n",
            "  Recall: 0.343244\n",
            "  F1 Score: 0.509670\n",
            "  Noise Detected (%): 34.324398\n",
            "\n",
            "Testing feature combination: ['magnitude', 'height']\n",
            "Fold 1 Results - Features: ['magnitude', 'height']\n",
            "  Precision: 0.990655\n",
            "  Recall: 0.343973\n",
            "  F1 Score: 0.510642\n",
            "  Noise Detected (%): 34.397331\n",
            "Fold 2 Results - Features: ['magnitude', 'height']\n",
            "  Precision: 0.990537\n",
            "  Recall: 0.343802\n",
            "  F1 Score: 0.510438\n",
            "  Noise Detected (%): 34.380173\n",
            "Fold 3 Results - Features: ['magnitude', 'height']\n",
            "  Precision: 0.988572\n",
            "  Recall: 0.341433\n",
            "  F1 Score: 0.507564\n",
            "  Noise Detected (%): 34.143317\n",
            "Fold 4 Results - Features: ['magnitude', 'height']\n",
            "  Precision: 0.988236\n",
            "  Recall: 0.344516\n",
            "  F1 Score: 0.510917\n",
            "  Noise Detected (%): 34.451592\n",
            "Fold 5 Results - Features: ['magnitude', 'height']\n",
            "  Precision: 0.992138\n",
            "  Recall: 0.344835\n",
            "  F1 Score: 0.511789\n",
            "  Noise Detected (%): 34.483501\n",
            "\n",
            "Testing feature combination: ['magnitude', 'weight']\n",
            "Fold 1 Results - Features: ['magnitude', 'weight']\n",
            "  Precision: 0.992191\n",
            "  Recall: 0.342582\n",
            "  F1 Score: 0.509310\n",
            "  Noise Detected (%): 34.258174\n",
            "Fold 2 Results - Features: ['magnitude', 'weight']\n",
            "  Precision: 0.992013\n",
            "  Recall: 0.342070\n",
            "  F1 Score: 0.508721\n",
            "  Noise Detected (%): 34.207022\n",
            "Fold 3 Results - Features: ['magnitude', 'weight']\n",
            "  Precision: 0.991692\n",
            "  Recall: 0.341493\n",
            "  F1 Score: 0.508041\n",
            "  Noise Detected (%): 34.149323\n",
            "Fold 4 Results - Features: ['magnitude', 'weight']\n",
            "  Precision: 0.992213\n",
            "  Recall: 0.341954\n",
            "  F1 Score: 0.508619\n",
            "  Noise Detected (%): 34.195410\n",
            "Fold 5 Results - Features: ['magnitude', 'weight']\n",
            "  Precision: 0.992239\n",
            "  Recall: 0.340202\n",
            "  F1 Score: 0.506681\n",
            "  Noise Detected (%): 34.020169\n",
            "\n",
            "Testing feature combination: ['magnitude', 'activity']\n",
            "Fold 1 Results - Features: ['magnitude', 'activity']\n",
            "  Precision: 0.970591\n",
            "  Recall: 0.340030\n",
            "  F1 Score: 0.503624\n",
            "  Noise Detected (%): 34.003026\n",
            "Fold 2 Results - Features: ['magnitude', 'activity']\n",
            "  Precision: 0.951850\n",
            "  Recall: 0.339963\n",
            "  F1 Score: 0.500992\n",
            "  Noise Detected (%): 33.996294\n",
            "Fold 3 Results - Features: ['magnitude', 'activity']\n",
            "  Precision: 0.978149\n",
            "  Recall: 0.334019\n",
            "  F1 Score: 0.497985\n",
            "  Noise Detected (%): 33.401880\n",
            "Fold 4 Results - Features: ['magnitude', 'activity']\n",
            "  Precision: 0.982683\n",
            "  Recall: 0.335648\n",
            "  F1 Score: 0.500384\n",
            "  Noise Detected (%): 33.564798\n",
            "Fold 5 Results - Features: ['magnitude', 'activity']\n",
            "  Precision: 0.969061\n",
            "  Recall: 0.335528\n",
            "  F1 Score: 0.498467\n",
            "  Noise Detected (%): 33.552842\n",
            "\n",
            "Testing feature combination: ['magnitude', 'age', 'gender']\n",
            "Fold 1 Results - Features: ['magnitude', 'age', 'gender']\n",
            "  Precision: 0.975695\n",
            "  Recall: 0.337806\n",
            "  F1 Score: 0.501858\n",
            "  Noise Detected (%): 33.780605\n",
            "Fold 2 Results - Features: ['magnitude', 'age', 'gender']\n",
            "  Precision: 0.958269\n",
            "  Recall: 0.317610\n",
            "  F1 Score: 0.477092\n",
            "  Noise Detected (%): 31.760955\n",
            "Fold 3 Results - Features: ['magnitude', 'age', 'gender']\n",
            "  Precision: 0.963352\n",
            "  Recall: 0.335282\n",
            "  F1 Score: 0.497437\n",
            "  Noise Detected (%): 33.528179\n",
            "Fold 4 Results - Features: ['magnitude', 'age', 'gender']\n",
            "  Precision: 0.975594\n",
            "  Recall: 0.340038\n",
            "  F1 Score: 0.504304\n",
            "  Noise Detected (%): 34.003828\n",
            "Fold 5 Results - Features: ['magnitude', 'age', 'gender']\n",
            "  Precision: 0.972418\n",
            "  Recall: 0.340684\n",
            "  F1 Score: 0.504587\n",
            "  Noise Detected (%): 34.068371\n",
            "\n",
            "Testing feature combination: ['magnitude', 'age', 'height']\n",
            "Fold 1 Results - Features: ['magnitude', 'age', 'height']\n",
            "  Precision: 0.978632\n",
            "  Recall: 0.338871\n",
            "  F1 Score: 0.503422\n",
            "  Noise Detected (%): 33.887080\n",
            "Fold 2 Results - Features: ['magnitude', 'age', 'height']\n",
            "  Precision: 0.977122\n",
            "  Recall: 0.337245\n",
            "  F1 Score: 0.501427\n",
            "  Noise Detected (%): 33.724545\n",
            "Fold 3 Results - Features: ['magnitude', 'age', 'height']\n",
            "  Precision: 0.977453\n",
            "  Recall: 0.336945\n",
            "  F1 Score: 0.501139\n",
            "  Noise Detected (%): 33.694521\n",
            "Fold 4 Results - Features: ['magnitude', 'age', 'height']\n",
            "  Precision: 0.965765\n",
            "  Recall: 0.338897\n",
            "  F1 Score: 0.501732\n",
            "  Noise Detected (%): 33.889734\n",
            "Fold 5 Results - Features: ['magnitude', 'age', 'height']\n",
            "  Precision: 0.976336\n",
            "  Recall: 0.340210\n",
            "  F1 Score: 0.504592\n",
            "  Noise Detected (%): 34.021042\n",
            "\n",
            "Testing feature combination: ['magnitude', 'age', 'weight']\n",
            "Fold 1 Results - Features: ['magnitude', 'age', 'weight']\n",
            "  Precision: 0.966518\n",
            "  Recall: 0.336240\n",
            "  F1 Score: 0.498914\n",
            "  Noise Detected (%): 33.624044\n",
            "Fold 2 Results - Features: ['magnitude', 'age', 'weight']\n",
            "  Precision: 0.979747\n",
            "  Recall: 0.337940\n",
            "  F1 Score: 0.502541\n",
            "  Noise Detected (%): 33.794044\n",
            "Fold 3 Results - Features: ['magnitude', 'age', 'weight']\n",
            "  Precision: 0.978516\n",
            "  Recall: 0.338133\n",
            "  F1 Score: 0.502591\n",
            "  Noise Detected (%): 33.813255\n",
            "Fold 4 Results - Features: ['magnitude', 'age', 'weight']\n",
            "  Precision: 0.968625\n",
            "  Recall: 0.336583\n",
            "  F1 Score: 0.499573\n",
            "  Noise Detected (%): 33.658346\n",
            "Fold 5 Results - Features: ['magnitude', 'age', 'weight']\n",
            "  Precision: 0.978241\n",
            "  Recall: 0.338982\n",
            "  F1 Score: 0.503493\n",
            "  Noise Detected (%): 33.898239\n",
            "\n",
            "Testing feature combination: ['magnitude', 'age', 'activity']\n",
            "Fold 1 Results - Features: ['magnitude', 'age', 'activity']\n",
            "  Precision: 0.970005\n",
            "  Recall: 0.336108\n",
            "  F1 Score: 0.499232\n",
            "  Noise Detected (%): 33.610838\n",
            "Fold 2 Results - Features: ['magnitude', 'age', 'activity']\n",
            "  Precision: 0.972828\n",
            "  Recall: 0.329961\n",
            "  F1 Score: 0.492782\n",
            "  Noise Detected (%): 32.996132\n",
            "Fold 3 Results - Features: ['magnitude', 'age', 'activity']\n",
            "  Precision: 0.972404\n",
            "  Recall: 0.330617\n",
            "  F1 Score: 0.493458\n",
            "  Noise Detected (%): 33.061661\n",
            "Fold 4 Results - Features: ['magnitude', 'age', 'activity']\n",
            "  Precision: 0.971883\n",
            "  Recall: 0.332176\n",
            "  F1 Score: 0.495125\n",
            "  Noise Detected (%): 33.217616\n",
            "Fold 5 Results - Features: ['magnitude', 'age', 'activity']\n",
            "  Precision: 0.973078\n",
            "  Recall: 0.329817\n",
            "  F1 Score: 0.492653\n",
            "  Noise Detected (%): 32.981724\n",
            "\n",
            "Testing feature combination: ['magnitude', 'gender', 'height']\n",
            "Fold 1 Results - Features: ['magnitude', 'gender', 'height']\n",
            "  Precision: 0.983900\n",
            "  Recall: 0.342215\n",
            "  F1 Score: 0.507807\n",
            "  Noise Detected (%): 34.221476\n",
            "Fold 2 Results - Features: ['magnitude', 'gender', 'height']\n",
            "  Precision: 0.984634\n",
            "  Recall: 0.339558\n",
            "  F1 Score: 0.504973\n",
            "  Noise Detected (%): 33.955808\n",
            "Fold 3 Results - Features: ['magnitude', 'gender', 'height']\n",
            "  Precision: 0.984946\n",
            "  Recall: 0.341850\n",
            "  F1 Score: 0.507544\n",
            "  Noise Detected (%): 34.185018\n",
            "Fold 4 Results - Features: ['magnitude', 'gender', 'height']\n",
            "  Precision: 0.985179\n",
            "  Recall: 0.342327\n",
            "  F1 Score: 0.508100\n",
            "  Noise Detected (%): 34.232680\n",
            "Fold 5 Results - Features: ['magnitude', 'gender', 'height']\n",
            "  Precision: 0.991296\n",
            "  Recall: 0.343908\n",
            "  F1 Score: 0.510655\n",
            "  Noise Detected (%): 34.390775\n",
            "\n",
            "Testing feature combination: ['magnitude', 'gender', 'weight']\n",
            "Fold 1 Results - Features: ['magnitude', 'gender', 'weight']\n",
            "  Precision: 0.985135\n",
            "  Recall: 0.341329\n",
            "  F1 Score: 0.506994\n",
            "  Noise Detected (%): 34.132857\n",
            "Fold 2 Results - Features: ['magnitude', 'gender', 'weight']\n",
            "  Precision: 0.990107\n",
            "  Recall: 0.341485\n",
            "  F1 Score: 0.507823\n",
            "  Noise Detected (%): 34.148478\n",
            "Fold 3 Results - Features: ['magnitude', 'gender', 'weight']\n",
            "  Precision: 0.984006\n",
            "  Recall: 0.342655\n",
            "  F1 Score: 0.508306\n",
            "  Noise Detected (%): 34.265524\n",
            "Fold 4 Results - Features: ['magnitude', 'gender', 'weight']\n",
            "  Precision: 0.981425\n",
            "  Recall: 0.341447\n",
            "  F1 Score: 0.506632\n",
            "  Noise Detected (%): 34.144718\n",
            "Fold 5 Results - Features: ['magnitude', 'gender', 'weight']\n",
            "  Precision: 0.991996\n",
            "  Recall: 0.343630\n",
            "  F1 Score: 0.510441\n",
            "  Noise Detected (%): 34.362967\n",
            "\n",
            "Testing feature combination: ['magnitude', 'gender', 'activity']\n",
            "Fold 1 Results - Features: ['magnitude', 'gender', 'activity']\n",
            "  Precision: 0.988148\n",
            "  Recall: 0.337065\n",
            "  F1 Score: 0.502667\n",
            "  Noise Detected (%): 33.706532\n",
            "Fold 2 Results - Features: ['magnitude', 'gender', 'activity']\n",
            "  Precision: 0.964820\n",
            "  Recall: 0.330946\n",
            "  F1 Score: 0.492841\n",
            "  Noise Detected (%): 33.094559\n",
            "Fold 3 Results - Features: ['magnitude', 'gender', 'activity']\n",
            "  Precision: 0.987400\n",
            "  Recall: 0.335046\n",
            "  F1 Score: 0.500322\n",
            "  Noise Detected (%): 33.504569\n",
            "Fold 4 Results - Features: ['magnitude', 'gender', 'activity']\n",
            "  Precision: 0.987618\n",
            "  Recall: 0.336637\n",
            "  F1 Score: 0.502122\n",
            "  Noise Detected (%): 33.663668\n",
            "Fold 5 Results - Features: ['magnitude', 'gender', 'activity']\n",
            "  Precision: 0.989481\n",
            "  Recall: 0.338757\n",
            "  F1 Score: 0.504719\n",
            "  Noise Detected (%): 33.875682\n",
            "\n",
            "Testing feature combination: ['magnitude', 'height', 'weight']\n",
            "Fold 1 Results - Features: ['magnitude', 'height', 'weight']\n",
            "  Precision: 0.985328\n",
            "  Recall: 0.341925\n",
            "  F1 Score: 0.507677\n",
            "  Noise Detected (%): 34.192486\n",
            "Fold 2 Results - Features: ['magnitude', 'height', 'weight']\n",
            "  Precision: 0.985464\n",
            "  Recall: 0.342872\n",
            "  F1 Score: 0.508738\n",
            "  Noise Detected (%): 34.287163\n",
            "Fold 3 Results - Features: ['magnitude', 'height', 'weight']\n",
            "  Precision: 0.984660\n",
            "  Recall: 0.341757\n",
            "  F1 Score: 0.507404\n",
            "  Noise Detected (%): 34.175714\n",
            "Fold 4 Results - Features: ['magnitude', 'height', 'weight']\n",
            "  Precision: 0.980999\n",
            "  Recall: 0.344018\n",
            "  F1 Score: 0.509400\n",
            "  Noise Detected (%): 34.401836\n",
            "Fold 5 Results - Features: ['magnitude', 'height', 'weight']\n",
            "  Precision: 0.986468\n",
            "  Recall: 0.342078\n",
            "  F1 Score: 0.507998\n",
            "  Noise Detected (%): 34.207822\n",
            "\n",
            "Testing feature combination: ['magnitude', 'height', 'activity']\n",
            "Fold 1 Results - Features: ['magnitude', 'height', 'activity']\n",
            "  Precision: 0.988099\n",
            "  Recall: 0.337040\n",
            "  F1 Score: 0.502632\n",
            "  Noise Detected (%): 33.703983\n",
            "Fold 2 Results - Features: ['magnitude', 'height', 'activity']\n",
            "  Precision: 0.987618\n",
            "  Recall: 0.338459\n",
            "  F1 Score: 0.504146\n",
            "  Noise Detected (%): 33.845863\n",
            "Fold 3 Results - Features: ['magnitude', 'height', 'activity']\n",
            "  Precision: 0.968306\n",
            "  Recall: 0.333237\n",
            "  F1 Score: 0.495836\n",
            "  Noise Detected (%): 33.323748\n",
            "Fold 4 Results - Features: ['magnitude', 'height', 'activity']\n",
            "  Precision: 0.987767\n",
            "  Recall: 0.335154\n",
            "  F1 Score: 0.500490\n",
            "  Noise Detected (%): 33.515431\n",
            "Fold 5 Results - Features: ['magnitude', 'height', 'activity']\n",
            "  Precision: 0.987597\n",
            "  Recall: 0.336174\n",
            "  F1 Score: 0.501604\n",
            "  Noise Detected (%): 33.617393\n",
            "\n",
            "Testing feature combination: ['magnitude', 'weight', 'activity']\n",
            "Fold 1 Results - Features: ['magnitude', 'weight', 'activity']\n",
            "  Precision: 0.980254\n",
            "  Recall: 0.338125\n",
            "  F1 Score: 0.502812\n",
            "  Noise Detected (%): 33.812502\n",
            "Fold 2 Results - Features: ['magnitude', 'weight', 'activity']\n",
            "  Precision: 0.987215\n",
            "  Recall: 0.335639\n",
            "  F1 Score: 0.500959\n",
            "  Noise Detected (%): 33.563856\n",
            "Fold 3 Results - Features: ['magnitude', 'weight', 'activity']\n",
            "  Precision: 0.980839\n",
            "  Recall: 0.336565\n",
            "  F1 Score: 0.501162\n",
            "  Noise Detected (%): 33.656526\n",
            "Fold 4 Results - Features: ['magnitude', 'weight', 'activity']\n",
            "  Precision: 0.987442\n",
            "  Recall: 0.333974\n",
            "  F1 Score: 0.499131\n",
            "  Noise Detected (%): 33.397393\n",
            "Fold 5 Results - Features: ['magnitude', 'weight', 'activity']\n",
            "  Precision: 0.965252\n",
            "  Recall: 0.334750\n",
            "  F1 Score: 0.497104\n",
            "  Noise Detected (%): 33.475042\n",
            "\n",
            "Testing feature combination: ['magnitude', 'age', 'gender', 'height']\n",
            "Fold 1 Results - Features: ['magnitude', 'age', 'gender', 'height']\n",
            "  Precision: 0.974370\n",
            "  Recall: 0.340874\n",
            "  F1 Score: 0.505058\n",
            "  Noise Detected (%): 34.087372\n",
            "Fold 2 Results - Features: ['magnitude', 'age', 'gender', 'height']\n",
            "  Precision: 0.975599\n",
            "  Recall: 0.337158\n",
            "  F1 Score: 0.501130\n",
            "  Noise Detected (%): 33.715760\n",
            "Fold 3 Results - Features: ['magnitude', 'age', 'gender', 'height']\n",
            "  Precision: 0.972755\n",
            "  Recall: 0.339173\n",
            "  F1 Score: 0.502973\n",
            "  Noise Detected (%): 33.917332\n",
            "Fold 4 Results - Features: ['magnitude', 'age', 'gender', 'height']\n",
            "  Precision: 0.974317\n",
            "  Recall: 0.337765\n",
            "  F1 Score: 0.501630\n",
            "  Noise Detected (%): 33.776450\n",
            "Fold 5 Results - Features: ['magnitude', 'age', 'gender', 'height']\n",
            "  Precision: 0.974550\n",
            "  Recall: 0.337591\n",
            "  F1 Score: 0.501469\n",
            "  Noise Detected (%): 33.759079\n",
            "\n",
            "Testing feature combination: ['magnitude', 'age', 'gender', 'weight']\n",
            "Fold 1 Results - Features: ['magnitude', 'age', 'gender', 'weight']\n",
            "  Precision: 0.971043\n",
            "  Recall: 0.339966\n",
            "  F1 Score: 0.503614\n",
            "  Noise Detected (%): 33.996582\n",
            "Fold 2 Results - Features: ['magnitude', 'age', 'gender', 'weight']\n",
            "  Precision: 0.977281\n",
            "  Recall: 0.338587\n",
            "  F1 Score: 0.502930\n",
            "  Noise Detected (%): 33.858735\n",
            "Fold 3 Results - Features: ['magnitude', 'age', 'gender', 'weight']\n",
            "  Precision: 0.975988\n",
            "  Recall: 0.340702\n",
            "  F1 Score: 0.505087\n",
            "  Noise Detected (%): 34.070228\n",
            "Fold 4 Results - Features: ['magnitude', 'age', 'gender', 'weight']\n",
            "  Precision: 0.968982\n",
            "  Recall: 0.336096\n",
            "  F1 Score: 0.499083\n",
            "  Noise Detected (%): 33.609582\n",
            "Fold 5 Results - Features: ['magnitude', 'age', 'gender', 'weight']\n",
            "  Precision: 0.973026\n",
            "  Recall: 0.339643\n",
            "  F1 Score: 0.503526\n",
            "  Noise Detected (%): 33.964279\n",
            "\n",
            "Testing feature combination: ['magnitude', 'age', 'gender', 'activity']\n",
            "Fold 1 Results - Features: ['magnitude', 'age', 'gender', 'activity']\n",
            "  Precision: 0.958411\n",
            "  Recall: 0.335777\n",
            "  F1 Score: 0.497319\n",
            "  Noise Detected (%): 33.577686\n",
            "Fold 2 Results - Features: ['magnitude', 'age', 'gender', 'activity']\n",
            "  Precision: 0.941407\n",
            "  Recall: 0.335036\n",
            "  F1 Score: 0.494194\n",
            "  Noise Detected (%): 33.503624\n",
            "Fold 3 Results - Features: ['magnitude', 'age', 'gender', 'activity']\n",
            "  Precision: 0.975141\n",
            "  Recall: 0.335843\n",
            "  F1 Score: 0.499616\n",
            "  Noise Detected (%): 33.584299\n",
            "Fold 4 Results - Features: ['magnitude', 'age', 'gender', 'activity']\n",
            "  Precision: 0.958356\n",
            "  Recall: 0.328310\n",
            "  F1 Score: 0.489075\n",
            "  Noise Detected (%): 32.831028\n",
            "Fold 5 Results - Features: ['magnitude', 'age', 'gender', 'activity']\n",
            "  Precision: 0.975517\n",
            "  Recall: 0.334300\n",
            "  F1 Score: 0.497955\n",
            "  Noise Detected (%): 33.429960\n",
            "\n",
            "Testing feature combination: ['magnitude', 'age', 'height', 'weight']\n",
            "Fold 1 Results - Features: ['magnitude', 'age', 'height', 'weight']\n",
            "  Precision: 0.972765\n",
            "  Recall: 0.339979\n",
            "  F1 Score: 0.503860\n",
            "  Noise Detected (%): 33.997851\n",
            "Fold 2 Results - Features: ['magnitude', 'age', 'height', 'weight']\n",
            "  Precision: 0.978550\n",
            "  Recall: 0.336732\n",
            "  F1 Score: 0.501047\n",
            "  Noise Detected (%): 33.673158\n",
            "Fold 3 Results - Features: ['magnitude', 'age', 'height', 'weight']\n",
            "  Precision: 0.971106\n",
            "  Recall: 0.337902\n",
            "  F1 Score: 0.501355\n",
            "  Noise Detected (%): 33.790182\n",
            "Fold 4 Results - Features: ['magnitude', 'age', 'height', 'weight']\n",
            "  Precision: 0.971362\n",
            "  Recall: 0.339174\n",
            "  F1 Score: 0.502788\n",
            "  Noise Detected (%): 33.917397\n",
            "Fold 5 Results - Features: ['magnitude', 'age', 'height', 'weight']\n",
            "  Precision: 0.970362\n",
            "  Recall: 0.337935\n",
            "  F1 Score: 0.501292\n",
            "  Noise Detected (%): 33.793518\n",
            "\n",
            "Testing feature combination: ['magnitude', 'age', 'height', 'activity']\n",
            "Fold 1 Results - Features: ['magnitude', 'age', 'height', 'activity']\n",
            "  Precision: 0.976010\n",
            "  Recall: 0.329444\n",
            "  F1 Score: 0.492612\n",
            "  Noise Detected (%): 32.944439\n",
            "Fold 2 Results - Features: ['magnitude', 'age', 'height', 'activity']\n",
            "  Precision: 0.934050\n",
            "  Recall: 0.336795\n",
            "  F1 Score: 0.495078\n",
            "  Noise Detected (%): 33.679541\n",
            "Fold 3 Results - Features: ['magnitude', 'age', 'height', 'activity']\n",
            "  Precision: 0.962446\n",
            "  Recall: 0.333840\n",
            "  F1 Score: 0.495729\n",
            "  Noise Detected (%): 33.384020\n",
            "Fold 4 Results - Features: ['magnitude', 'age', 'height', 'activity']\n",
            "  Precision: 0.973674\n",
            "  Recall: 0.332063\n",
            "  F1 Score: 0.495232\n",
            "  Noise Detected (%): 33.206340\n",
            "Fold 5 Results - Features: ['magnitude', 'age', 'height', 'activity']\n",
            "  Precision: 0.965349\n",
            "  Recall: 0.334292\n",
            "  F1 Score: 0.496612\n",
            "  Noise Detected (%): 33.429242\n",
            "\n",
            "Testing feature combination: ['magnitude', 'age', 'weight', 'activity']\n",
            "Fold 1 Results - Features: ['magnitude', 'age', 'weight', 'activity']\n",
            "  Precision: 0.967128\n",
            "  Recall: 0.335343\n",
            "  F1 Score: 0.498006\n",
            "  Noise Detected (%): 33.534269\n",
            "Fold 2 Results - Features: ['magnitude', 'age', 'weight', 'activity']\n",
            "  Precision: 0.960702\n",
            "  Recall: 0.333156\n",
            "  F1 Score: 0.494743\n",
            "  Noise Detected (%): 33.315553\n",
            "Fold 3 Results - Features: ['magnitude', 'age', 'weight', 'activity']\n",
            "  Precision: 0.972746\n",
            "  Recall: 0.326355\n",
            "  F1 Score: 0.488738\n",
            "  Noise Detected (%): 32.635463\n",
            "Fold 4 Results - Features: ['magnitude', 'age', 'weight', 'activity']\n",
            "  Precision: 0.956527\n",
            "  Recall: 0.330335\n",
            "  F1 Score: 0.491078\n",
            "  Noise Detected (%): 33.033541\n",
            "Fold 5 Results - Features: ['magnitude', 'age', 'weight', 'activity']\n",
            "  Precision: 0.967419\n",
            "  Recall: 0.324029\n",
            "  F1 Score: 0.485458\n",
            "  Noise Detected (%): 32.402903\n",
            "\n",
            "Testing feature combination: ['magnitude', 'gender', 'height', 'weight']\n",
            "Fold 1 Results - Features: ['magnitude', 'gender', 'height', 'weight']\n",
            "  Precision: 0.986150\n",
            "  Recall: 0.342036\n",
            "  F1 Score: 0.507909\n",
            "  Noise Detected (%): 34.203553\n",
            "Fold 2 Results - Features: ['magnitude', 'gender', 'height', 'weight']\n",
            "  Precision: 0.984062\n",
            "  Recall: 0.341042\n",
            "  F1 Score: 0.506536\n",
            "  Noise Detected (%): 34.104174\n",
            "Fold 3 Results - Features: ['magnitude', 'gender', 'height', 'weight']\n",
            "  Precision: 0.978360\n",
            "  Recall: 0.339945\n",
            "  F1 Score: 0.504570\n",
            "  Noise Detected (%): 33.994475\n",
            "Fold 4 Results - Features: ['magnitude', 'gender', 'height', 'weight']\n",
            "  Precision: 0.990167\n",
            "  Recall: 0.342731\n",
            "  F1 Score: 0.509208\n",
            "  Noise Detected (%): 34.273102\n",
            "Fold 5 Results - Features: ['magnitude', 'gender', 'height', 'weight']\n",
            "  Precision: 0.984407\n",
            "  Recall: 0.341544\n",
            "  F1 Score: 0.507135\n",
            "  Noise Detected (%): 34.154398\n",
            "\n",
            "Testing feature combination: ['magnitude', 'gender', 'height', 'activity']\n",
            "Fold 1 Results - Features: ['magnitude', 'gender', 'height', 'activity']\n",
            "  Precision: 0.981932\n",
            "  Recall: 0.333991\n",
            "  F1 Score: 0.498443\n",
            "  Noise Detected (%): 33.399078\n",
            "Fold 2 Results - Features: ['magnitude', 'gender', 'height', 'activity']\n",
            "  Precision: 0.982980\n",
            "  Recall: 0.334978\n",
            "  F1 Score: 0.499677\n",
            "  Noise Detected (%): 33.497813\n",
            "Fold 3 Results - Features: ['magnitude', 'gender', 'height', 'activity']\n",
            "  Precision: 0.981485\n",
            "  Recall: 0.335009\n",
            "  F1 Score: 0.499518\n",
            "  Noise Detected (%): 33.500865\n",
            "Fold 4 Results - Features: ['magnitude', 'gender', 'height', 'activity']\n",
            "  Precision: 0.979152\n",
            "  Recall: 0.336091\n",
            "  F1 Score: 0.500416\n",
            "  Noise Detected (%): 33.609091\n",
            "Fold 5 Results - Features: ['magnitude', 'gender', 'height', 'activity']\n",
            "  Precision: 0.982052\n",
            "  Recall: 0.335228\n",
            "  F1 Score: 0.499835\n",
            "  Noise Detected (%): 33.522812\n",
            "\n",
            "Testing feature combination: ['magnitude', 'gender', 'weight', 'activity']\n",
            "Fold 1 Results - Features: ['magnitude', 'gender', 'weight', 'activity']\n",
            "  Precision: 0.964650\n",
            "  Recall: 0.332824\n",
            "  F1 Score: 0.494898\n",
            "  Noise Detected (%): 33.282380\n",
            "Fold 2 Results - Features: ['magnitude', 'gender', 'weight', 'activity']\n",
            "  Precision: 0.973872\n",
            "  Recall: 0.332148\n",
            "  F1 Score: 0.495352\n",
            "  Noise Detected (%): 33.214824\n",
            "Fold 3 Results - Features: ['magnitude', 'gender', 'weight', 'activity']\n",
            "  Precision: 0.960808\n",
            "  Recall: 0.322890\n",
            "  F1 Score: 0.483347\n",
            "  Noise Detected (%): 32.289042\n",
            "Fold 4 Results - Features: ['magnitude', 'gender', 'weight', 'activity']\n",
            "  Precision: 0.981366\n",
            "  Recall: 0.339326\n",
            "  F1 Score: 0.504286\n",
            "  Noise Detected (%): 33.932636\n",
            "Fold 5 Results - Features: ['magnitude', 'gender', 'weight', 'activity']\n",
            "  Precision: 0.960509\n",
            "  Recall: 0.322713\n",
            "  F1 Score: 0.483111\n",
            "  Noise Detected (%): 32.271343\n",
            "\n",
            "Testing feature combination: ['magnitude', 'height', 'weight', 'activity']\n",
            "Fold 1 Results - Features: ['magnitude', 'height', 'weight', 'activity']\n",
            "  Precision: 0.950990\n",
            "  Recall: 0.337748\n",
            "  F1 Score: 0.498464\n",
            "  Noise Detected (%): 33.774778\n",
            "Fold 2 Results - Features: ['magnitude', 'height', 'weight', 'activity']\n",
            "  Precision: 0.982371\n",
            "  Recall: 0.338477\n",
            "  F1 Score: 0.503479\n",
            "  Noise Detected (%): 33.847656\n",
            "Fold 3 Results - Features: ['magnitude', 'height', 'weight', 'activity']\n",
            "  Precision: 0.963136\n",
            "  Recall: 0.333030\n",
            "  F1 Score: 0.494926\n",
            "  Noise Detected (%): 33.302953\n",
            "Fold 4 Results - Features: ['magnitude', 'height', 'weight', 'activity']\n",
            "  Precision: 0.982389\n",
            "  Recall: 0.334042\n",
            "  F1 Score: 0.498559\n",
            "  Noise Detected (%): 33.404206\n",
            "Fold 5 Results - Features: ['magnitude', 'height', 'weight', 'activity']\n",
            "  Precision: 0.983514\n",
            "  Recall: 0.335607\n",
            "  F1 Score: 0.500446\n",
            "  Noise Detected (%): 33.560740\n",
            "\n",
            "Testing feature combination: ['magnitude', 'age', 'gender', 'height', 'weight']\n",
            "Fold 1 Results - Features: ['magnitude', 'age', 'gender', 'height', 'weight']\n",
            "  Precision: 0.970485\n",
            "  Recall: 0.337635\n",
            "  F1 Score: 0.500978\n",
            "  Noise Detected (%): 33.763453\n",
            "Fold 2 Results - Features: ['magnitude', 'age', 'gender', 'height', 'weight']\n",
            "  Precision: 0.970978\n",
            "  Recall: 0.340535\n",
            "  F1 Score: 0.504230\n",
            "  Noise Detected (%): 34.053513\n",
            "Fold 3 Results - Features: ['magnitude', 'age', 'gender', 'height', 'weight']\n",
            "  Precision: 0.966782\n",
            "  Recall: 0.333984\n",
            "  F1 Score: 0.496461\n",
            "  Noise Detected (%): 33.398429\n",
            "Fold 4 Results - Features: ['magnitude', 'age', 'gender', 'height', 'weight']\n",
            "  Precision: 0.960225\n",
            "  Recall: 0.328911\n",
            "  F1 Score: 0.489985\n",
            "  Noise Detected (%): 32.891097\n",
            "Fold 5 Results - Features: ['magnitude', 'age', 'gender', 'height', 'weight']\n",
            "  Precision: 0.963287\n",
            "  Recall: 0.326256\n",
            "  F1 Score: 0.487426\n",
            "  Noise Detected (%): 32.625627\n",
            "\n",
            "Testing feature combination: ['magnitude', 'age', 'gender', 'height', 'activity']\n",
            "Fold 1 Results - Features: ['magnitude', 'age', 'gender', 'height', 'activity']\n",
            "  Precision: 0.958629\n",
            "  Recall: 0.334346\n",
            "  F1 Score: 0.495777\n",
            "  Noise Detected (%): 33.434603\n",
            "Fold 2 Results - Features: ['magnitude', 'age', 'gender', 'height', 'activity']\n",
            "  Precision: 0.960455\n",
            "  Recall: 0.332669\n",
            "  F1 Score: 0.494173\n",
            "  Noise Detected (%): 33.266869\n",
            "Fold 3 Results - Features: ['magnitude', 'age', 'gender', 'height', 'activity']\n",
            "  Precision: 0.969281\n",
            "  Recall: 0.327265\n",
            "  F1 Score: 0.489318\n",
            "  Noise Detected (%): 32.726456\n",
            "Fold 4 Results - Features: ['magnitude', 'age', 'gender', 'height', 'activity']\n",
            "  Precision: 0.969668\n",
            "  Recall: 0.329302\n",
            "  F1 Score: 0.491641\n",
            "  Noise Detected (%): 32.930208\n",
            "Fold 5 Results - Features: ['magnitude', 'age', 'gender', 'height', 'activity']\n",
            "  Precision: 0.980360\n",
            "  Recall: 0.338290\n",
            "  F1 Score: 0.503008\n",
            "  Noise Detected (%): 33.828989\n",
            "\n",
            "Testing feature combination: ['magnitude', 'age', 'gender', 'weight', 'activity']\n",
            "Fold 1 Results - Features: ['magnitude', 'age', 'gender', 'weight', 'activity']\n",
            "  Precision: 0.972782\n",
            "  Recall: 0.327892\n",
            "  F1 Score: 0.490465\n",
            "  Noise Detected (%): 32.789231\n",
            "Fold 2 Results - Features: ['magnitude', 'age', 'gender', 'weight', 'activity']\n",
            "  Precision: 0.967629\n",
            "  Recall: 0.328391\n",
            "  F1 Score: 0.490363\n",
            "  Noise Detected (%): 32.839054\n",
            "Fold 3 Results - Features: ['magnitude', 'age', 'gender', 'weight', 'activity']\n",
            "  Precision: 0.972150\n",
            "  Recall: 0.327815\n",
            "  F1 Score: 0.490298\n",
            "  Noise Detected (%): 32.781479\n",
            "Fold 4 Results - Features: ['magnitude', 'age', 'gender', 'weight', 'activity']\n",
            "  Precision: 0.969078\n",
            "  Recall: 0.335169\n",
            "  F1 Score: 0.498072\n",
            "  Noise Detected (%): 33.516868\n",
            "Fold 5 Results - Features: ['magnitude', 'age', 'gender', 'weight', 'activity']\n",
            "  Precision: 0.963636\n",
            "  Recall: 0.333694\n",
            "  F1 Score: 0.495725\n",
            "  Noise Detected (%): 33.369398\n",
            "\n",
            "Testing feature combination: ['magnitude', 'age', 'height', 'weight', 'activity']\n",
            "Fold 1 Results - Features: ['magnitude', 'age', 'height', 'weight', 'activity']\n",
            "  Precision: 0.967263\n",
            "  Recall: 0.332742\n",
            "  F1 Score: 0.495150\n",
            "  Noise Detected (%): 33.274177\n",
            "Fold 2 Results - Features: ['magnitude', 'age', 'height', 'weight', 'activity']\n",
            "  Precision: 0.961645\n",
            "  Recall: 0.337796\n",
            "  F1 Score: 0.499969\n",
            "  Noise Detected (%): 33.779604\n",
            "Fold 3 Results - Features: ['magnitude', 'age', 'height', 'weight', 'activity']\n",
            "  Precision: 0.962166\n",
            "  Recall: 0.335165\n",
            "  F1 Score: 0.497151\n",
            "  Noise Detected (%): 33.516544\n",
            "Fold 4 Results - Features: ['magnitude', 'age', 'height', 'weight', 'activity']\n",
            "  Precision: 0.965343\n",
            "  Recall: 0.327841\n",
            "  F1 Score: 0.489457\n",
            "  Noise Detected (%): 32.784114\n",
            "Fold 5 Results - Features: ['magnitude', 'age', 'height', 'weight', 'activity']\n",
            "  Precision: 0.968215\n",
            "  Recall: 0.329300\n",
            "  F1 Score: 0.491452\n",
            "  Noise Detected (%): 32.930036\n",
            "\n",
            "Testing feature combination: ['magnitude', 'gender', 'height', 'weight', 'activity']\n",
            "Fold 1 Results - Features: ['magnitude', 'gender', 'height', 'weight', 'activity']\n",
            "  Precision: 0.983384\n",
            "  Recall: 0.335444\n",
            "  F1 Score: 0.500248\n",
            "  Noise Detected (%): 33.544444\n",
            "Fold 2 Results - Features: ['magnitude', 'gender', 'height', 'weight', 'activity']\n",
            "  Precision: 0.972978\n",
            "  Recall: 0.331754\n",
            "  F1 Score: 0.494798\n",
            "  Noise Detected (%): 33.175436\n",
            "Fold 3 Results - Features: ['magnitude', 'gender', 'height', 'weight', 'activity']\n",
            "  Precision: 0.964332\n",
            "  Recall: 0.329983\n",
            "  F1 Score: 0.491710\n",
            "  Noise Detected (%): 32.998345\n",
            "Fold 4 Results - Features: ['magnitude', 'gender', 'height', 'weight', 'activity']\n",
            "  Precision: 0.983752\n",
            "  Recall: 0.336837\n",
            "  F1 Score: 0.501842\n",
            "  Noise Detected (%): 33.683657\n",
            "Fold 5 Results - Features: ['magnitude', 'gender', 'height', 'weight', 'activity']\n",
            "  Precision: 0.971121\n",
            "  Recall: 0.335068\n",
            "  F1 Score: 0.498230\n",
            "  Noise Detected (%): 33.506774\n",
            "\n",
            "Testing feature combination: ['magnitude', 'age', 'gender', 'height', 'weight', 'activity']\n",
            "Fold 1 Results - Features: ['magnitude', 'age', 'gender', 'height', 'weight', 'activity']\n",
            "  Precision: 0.966859\n",
            "  Recall: 0.328391\n",
            "  F1 Score: 0.490265\n",
            "  Noise Detected (%): 32.839136\n",
            "Fold 2 Results - Features: ['magnitude', 'age', 'gender', 'height', 'weight', 'activity']\n",
            "  Precision: 0.961619\n",
            "  Recall: 0.335217\n",
            "  F1 Score: 0.497135\n",
            "  Noise Detected (%): 33.521717\n",
            "Fold 3 Results - Features: ['magnitude', 'age', 'gender', 'height', 'weight', 'activity']\n",
            "  Precision: 0.956432\n",
            "  Recall: 0.334189\n",
            "  F1 Score: 0.495311\n",
            "  Noise Detected (%): 33.418921\n",
            "Fold 4 Results - Features: ['magnitude', 'age', 'gender', 'height', 'weight', 'activity']\n",
            "  Precision: 0.979669\n",
            "  Recall: 0.334673\n",
            "  F1 Score: 0.498909\n",
            "  Noise Detected (%): 33.467278\n",
            "Fold 5 Results - Features: ['magnitude', 'age', 'gender', 'height', 'weight', 'activity']\n",
            "  Precision: 0.975635\n",
            "  Recall: 0.334038\n",
            "  F1 Score: 0.497680\n",
            "  Noise Detected (%): 33.403775\n",
            "\n",
            "Feature Selection Results (sorted by Avg F1 Score):\n",
            "                                            Features  Avg F1 Score  Precision  \\\n",
            "0                                          magnitude      0.512768   0.995984   \n",
            "2                                  magnitude, gender      0.510476   0.989384   \n",
            "3                                  magnitude, height      0.510270   0.992138   \n",
            "4                                  magnitude, weight      0.508274   0.992239   \n",
            "13                         magnitude, height, weight      0.508243   0.986468   \n",
            "11                         magnitude, gender, weight      0.508039   0.991996   \n",
            "10                         magnitude, gender, height      0.507816   0.991296   \n",
            "22                 magnitude, gender, height, weight      0.507071   0.984407   \n",
            "1                                     magnitude, age      0.505246   0.981582   \n",
            "17                    magnitude, age, gender, weight      0.502848   0.973026   \n",
            "7                             magnitude, age, height      0.502462   0.976336   \n",
            "16                    magnitude, age, gender, height      0.502452   0.974550   \n",
            "19                    magnitude, age, height, weight      0.502068   0.970362   \n",
            "8                             magnitude, age, weight      0.501423   0.978241   \n",
            "14                       magnitude, height, activity      0.500941   0.987597   \n",
            "12                       magnitude, gender, activity      0.500534   0.989481   \n",
            "5                                magnitude, activity      0.500290   0.969061   \n",
            "15                       magnitude, weight, activity      0.500234   0.965252   \n",
            "23               magnitude, gender, height, activity      0.499578   0.982052   \n",
            "25               magnitude, height, weight, activity      0.499175   0.983514   \n",
            "30       magnitude, gender, height, weight, activity      0.497366   0.971121   \n",
            "6                             magnitude, age, gender      0.497056   0.972418   \n",
            "31  magnitude, age, gender, height, weight, activity      0.495860   0.975635   \n",
            "26            magnitude, age, gender, height, weight      0.495816   0.963287   \n",
            "18                  magnitude, age, gender, activity      0.495632   0.975517   \n",
            "20                  magnitude, age, height, activity      0.495052   0.965349   \n",
            "27          magnitude, age, gender, height, activity      0.494783   0.980360   \n",
            "9                           magnitude, age, activity      0.494650   0.973078   \n",
            "29          magnitude, age, height, weight, activity      0.494636   0.968215   \n",
            "28          magnitude, age, gender, weight, activity      0.492985   0.963636   \n",
            "24               magnitude, gender, weight, activity      0.492199   0.960509   \n",
            "21                  magnitude, age, weight, activity      0.491605   0.967419   \n",
            "\n",
            "      Recall  Noise Detected (%)  \n",
            "0   0.347615           34.761492  \n",
            "2   0.343244           34.324398  \n",
            "3   0.344835           34.483501  \n",
            "4   0.340202           34.020169  \n",
            "13  0.342078           34.207822  \n",
            "11  0.343630           34.362967  \n",
            "10  0.343908           34.390775  \n",
            "22  0.341544           34.154398  \n",
            "1   0.341153           34.115338  \n",
            "17  0.339643           33.964279  \n",
            "7   0.340210           34.021042  \n",
            "16  0.337591           33.759079  \n",
            "19  0.337935           33.793518  \n",
            "8   0.338982           33.898239  \n",
            "14  0.336174           33.617393  \n",
            "12  0.338757           33.875682  \n",
            "5   0.335528           33.552842  \n",
            "15  0.334750           33.475042  \n",
            "23  0.335228           33.522812  \n",
            "25  0.335607           33.560740  \n",
            "30  0.335068           33.506774  \n",
            "6   0.340684           34.068371  \n",
            "31  0.334038           33.403775  \n",
            "26  0.326256           32.625627  \n",
            "18  0.334300           33.429960  \n",
            "20  0.334292           33.429242  \n",
            "27  0.338290           33.828989  \n",
            "9   0.329817           32.981724  \n",
            "29  0.329300           32.930036  \n",
            "28  0.333694           33.369398  \n",
            "24  0.322713           32.271343  \n",
            "21  0.324029           32.402903  \n",
            "Feature selection results saved to '/content/drive/My Drive/ColabNotebooks/feature_selection_results.csv'.\n"
          ]
        }
      ]
    }
  ]
}